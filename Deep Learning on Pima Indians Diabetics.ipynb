{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some exercises with Keras using a Kaggle dataset\n",
    "\n",
    "For computational reasons, let's use this dataset which describes the medical records for Pima Indians and whether or not each patient will have an onset of diabetes within five years [more info](https://www.kaggle.com/kumargh/pimaindiansdiabetescsv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pima indians dataset\n",
    "dataset = np.loadtxt(\"data/data_pima_indians_diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.000e+00, 1.480e+02, 7.200e+01, 3.500e+01, 0.000e+00, 3.360e+01,\n",
       "        6.270e-01, 5.000e+01, 1.000e+00],\n",
       "       [1.000e+00, 8.500e+01, 6.600e+01, 2.900e+01, 0.000e+00, 2.660e+01,\n",
       "        3.510e-01, 3.100e+01, 0.000e+00],\n",
       "       [8.000e+00, 1.830e+02, 6.400e+01, 0.000e+00, 0.000e+00, 2.330e+01,\n",
       "        6.720e-01, 3.200e+01, 1.000e+00],\n",
       "       [1.000e+00, 8.900e+01, 6.600e+01, 2.300e+01, 9.400e+01, 2.810e+01,\n",
       "        1.670e-01, 2.100e+01, 0.000e+00],\n",
       "       [0.000e+00, 1.370e+02, 4.000e+01, 3.500e+01, 1.680e+02, 4.310e+01,\n",
       "        2.288e+00, 3.300e+01, 1.000e+00]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.000e+00, 1.480e+02, 7.200e+01, 3.500e+01, 0.000e+00, 3.360e+01,\n",
       "        6.270e-01, 5.000e+01],\n",
       "       [1.000e+00, 8.500e+01, 6.600e+01, 2.900e+01, 0.000e+00, 2.660e+01,\n",
       "        3.510e-01, 3.100e+01],\n",
       "       [8.000e+00, 1.830e+02, 6.400e+01, 0.000e+00, 0.000e+00, 2.330e+01,\n",
       "        6.720e-01, 3.200e+01],\n",
       "       [1.000e+00, 8.900e+01, 6.600e+01, 2.300e+01, 9.400e+01, 2.810e+01,\n",
       "        1.670e-01, 2.100e+01],\n",
       "       [0.000e+00, 1.370e+02, 4.000e+01, 3.500e+01, 1.680e+02, 4.310e+01,\n",
       "        2.288e+00, 3.300e+01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer='rmsprop', init='glorot_uniform'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, init=init, activation='relu'))\n",
    "    model.add(Dense(8, init=init, activation='relu'))\n",
    "    model.add(Dense(1, init=init, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-21c09937675e>:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(12, input_dim=8, init=init, activation='relu'))\n",
      "<ipython-input-8-21c09937675e>:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(8, init=init, activation='relu'))\n",
      "<ipython-input-8-21c09937675e>:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(1, init=init, activation='sigmoid'))\n",
      "<ipython-input-9-811ff480d80f>:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  history = model.fit(X, Y, validation_split=0.33, nb_epoch=150, batch_size=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 514 samples, validate on 254 samples\n",
      "Epoch 1/150\n",
      "514/514 [==============================] - 0s 584us/step - loss: 3.2770 - accuracy: 0.5817 - val_loss: 1.1252 - val_accuracy: 0.5354\n",
      "Epoch 2/150\n",
      "514/514 [==============================] - 0s 117us/step - loss: 0.9837 - accuracy: 0.5895 - val_loss: 1.1768 - val_accuracy: 0.5630\n",
      "Epoch 3/150\n",
      "514/514 [==============================] - 0s 117us/step - loss: 0.8629 - accuracy: 0.6323 - val_loss: 1.0001 - val_accuracy: 0.6142\n",
      "Epoch 4/150\n",
      "514/514 [==============================] - 0s 102us/step - loss: 0.7872 - accuracy: 0.6673 - val_loss: 0.9076 - val_accuracy: 0.6654\n",
      "Epoch 5/150\n",
      "514/514 [==============================] - 0s 108us/step - loss: 0.7711 - accuracy: 0.6459 - val_loss: 0.8165 - val_accuracy: 0.6024\n",
      "Epoch 6/150\n",
      "514/514 [==============================] - 0s 112us/step - loss: 0.7384 - accuracy: 0.6693 - val_loss: 0.9302 - val_accuracy: 0.6417\n",
      "Epoch 7/150\n",
      "514/514 [==============================] - 0s 110us/step - loss: 0.7235 - accuracy: 0.6732 - val_loss: 0.7757 - val_accuracy: 0.6496\n",
      "Epoch 8/150\n",
      "514/514 [==============================] - 0s 116us/step - loss: 0.7118 - accuracy: 0.6654 - val_loss: 0.8500 - val_accuracy: 0.6417\n",
      "Epoch 9/150\n",
      "514/514 [==============================] - 0s 129us/step - loss: 0.6958 - accuracy: 0.6673 - val_loss: 1.0288 - val_accuracy: 0.4331\n",
      "Epoch 10/150\n",
      "514/514 [==============================] - 0s 100us/step - loss: 0.6993 - accuracy: 0.6693 - val_loss: 0.7777 - val_accuracy: 0.6260\n",
      "Epoch 11/150\n",
      "514/514 [==============================] - 0s 106us/step - loss: 0.6885 - accuracy: 0.6809 - val_loss: 1.0870 - val_accuracy: 0.4173\n",
      "Epoch 12/150\n",
      "514/514 [==============================] - 0s 100us/step - loss: 0.6770 - accuracy: 0.6770 - val_loss: 0.7743 - val_accuracy: 0.5748\n",
      "Epoch 13/150\n",
      "514/514 [==============================] - 0s 107us/step - loss: 0.6837 - accuracy: 0.6809 - val_loss: 0.8160 - val_accuracy: 0.6772\n",
      "Epoch 14/150\n",
      "514/514 [==============================] - 0s 114us/step - loss: 0.6753 - accuracy: 0.6790 - val_loss: 0.8675 - val_accuracy: 0.6614\n",
      "Epoch 15/150\n",
      "514/514 [==============================] - 0s 106us/step - loss: 0.6844 - accuracy: 0.6809 - val_loss: 0.6994 - val_accuracy: 0.5827\n",
      "Epoch 16/150\n",
      "514/514 [==============================] - 0s 118us/step - loss: 0.6529 - accuracy: 0.6809 - val_loss: 0.6720 - val_accuracy: 0.6496\n",
      "Epoch 17/150\n",
      "514/514 [==============================] - 0s 104us/step - loss: 0.6576 - accuracy: 0.6848 - val_loss: 0.7048 - val_accuracy: 0.6614\n",
      "Epoch 18/150\n",
      "514/514 [==============================] - 0s 102us/step - loss: 0.6495 - accuracy: 0.7004 - val_loss: 0.6641 - val_accuracy: 0.6535\n",
      "Epoch 19/150\n",
      "514/514 [==============================] - 0s 107us/step - loss: 0.6500 - accuracy: 0.6965 - val_loss: 0.6981 - val_accuracy: 0.6772\n",
      "Epoch 20/150\n",
      "514/514 [==============================] - 0s 105us/step - loss: 0.6307 - accuracy: 0.7004 - val_loss: 0.8458 - val_accuracy: 0.6732\n",
      "Epoch 21/150\n",
      "514/514 [==============================] - 0s 112us/step - loss: 0.6266 - accuracy: 0.7004 - val_loss: 0.6798 - val_accuracy: 0.6220\n",
      "Epoch 22/150\n",
      "514/514 [==============================] - 0s 108us/step - loss: 0.6263 - accuracy: 0.7082 - val_loss: 0.7012 - val_accuracy: 0.5709\n",
      "Epoch 23/150\n",
      "514/514 [==============================] - 0s 111us/step - loss: 0.6215 - accuracy: 0.6732 - val_loss: 0.6248 - val_accuracy: 0.6732\n",
      "Epoch 24/150\n",
      "514/514 [==============================] - 0s 100us/step - loss: 0.6260 - accuracy: 0.7062 - val_loss: 0.6491 - val_accuracy: 0.6457\n",
      "Epoch 25/150\n",
      "514/514 [==============================] - 0s 101us/step - loss: 0.6045 - accuracy: 0.6946 - val_loss: 0.7004 - val_accuracy: 0.6024\n",
      "Epoch 26/150\n",
      "514/514 [==============================] - 0s 111us/step - loss: 0.6058 - accuracy: 0.7218 - val_loss: 0.6363 - val_accuracy: 0.6850\n",
      "Epoch 27/150\n",
      "514/514 [==============================] - 0s 107us/step - loss: 0.5954 - accuracy: 0.6926 - val_loss: 0.7204 - val_accuracy: 0.6339\n",
      "Epoch 28/150\n",
      "514/514 [==============================] - 0s 109us/step - loss: 0.5875 - accuracy: 0.7140 - val_loss: 0.6270 - val_accuracy: 0.6890\n",
      "Epoch 29/150\n",
      "514/514 [==============================] - 0s 113us/step - loss: 0.6022 - accuracy: 0.7121 - val_loss: 0.8355 - val_accuracy: 0.6929\n",
      "Epoch 30/150\n",
      "514/514 [==============================] - 0s 109us/step - loss: 0.6300 - accuracy: 0.7023 - val_loss: 0.6096 - val_accuracy: 0.6811\n",
      "Epoch 31/150\n",
      "514/514 [==============================] - 0s 103us/step - loss: 0.6039 - accuracy: 0.6946 - val_loss: 0.6114 - val_accuracy: 0.7047\n",
      "Epoch 32/150\n",
      "514/514 [==============================] - 0s 108us/step - loss: 0.5887 - accuracy: 0.6984 - val_loss: 0.6293 - val_accuracy: 0.7087\n",
      "Epoch 33/150\n",
      "514/514 [==============================] - 0s 116us/step - loss: 0.5975 - accuracy: 0.7121 - val_loss: 0.6346 - val_accuracy: 0.6457\n",
      "Epoch 34/150\n",
      "514/514 [==============================] - 0s 99us/step - loss: 0.5953 - accuracy: 0.7043 - val_loss: 0.6231 - val_accuracy: 0.7126\n",
      "Epoch 35/150\n",
      "514/514 [==============================] - 0s 100us/step - loss: 0.5966 - accuracy: 0.7062 - val_loss: 0.6415 - val_accuracy: 0.6969\n",
      "Epoch 36/150\n",
      "514/514 [==============================] - 0s 100us/step - loss: 0.5746 - accuracy: 0.7296 - val_loss: 0.6050 - val_accuracy: 0.6929\n",
      "Epoch 37/150\n",
      "514/514 [==============================] - 0s 112us/step - loss: 0.5998 - accuracy: 0.7043 - val_loss: 0.7175 - val_accuracy: 0.5827\n",
      "Epoch 38/150\n",
      "514/514 [==============================] - 0s 108us/step - loss: 0.5972 - accuracy: 0.7043 - val_loss: 0.6621 - val_accuracy: 0.7008\n",
      "Epoch 39/150\n",
      "514/514 [==============================] - 0s 109us/step - loss: 0.5784 - accuracy: 0.7237 - val_loss: 0.7252 - val_accuracy: 0.7047\n",
      "Epoch 40/150\n",
      "514/514 [==============================] - 0s 113us/step - loss: 0.5798 - accuracy: 0.7257 - val_loss: 0.7045 - val_accuracy: 0.7087\n",
      "Epoch 41/150\n",
      "514/514 [==============================] - 0s 128us/step - loss: 0.5837 - accuracy: 0.7121 - val_loss: 0.6217 - val_accuracy: 0.7087\n",
      "Epoch 42/150\n",
      "514/514 [==============================] - 0s 106us/step - loss: 0.5736 - accuracy: 0.7179 - val_loss: 0.6078 - val_accuracy: 0.6890\n",
      "Epoch 43/150\n",
      "514/514 [==============================] - 0s 106us/step - loss: 0.5942 - accuracy: 0.6790 - val_loss: 0.6113 - val_accuracy: 0.6693\n",
      "Epoch 44/150\n",
      "514/514 [==============================] - 0s 103us/step - loss: 0.5720 - accuracy: 0.7296 - val_loss: 0.6109 - val_accuracy: 0.7008\n",
      "Epoch 45/150\n",
      "514/514 [==============================] - 0s 108us/step - loss: 0.5718 - accuracy: 0.7101 - val_loss: 0.5982 - val_accuracy: 0.6693\n",
      "Epoch 46/150\n",
      "514/514 [==============================] - 0s 103us/step - loss: 0.5892 - accuracy: 0.6984 - val_loss: 0.5792 - val_accuracy: 0.7205\n",
      "Epoch 47/150\n",
      "514/514 [==============================] - 0s 102us/step - loss: 0.5617 - accuracy: 0.7354 - val_loss: 0.6185 - val_accuracy: 0.6614\n",
      "Epoch 48/150\n",
      "514/514 [==============================] - 0s 106us/step - loss: 0.5757 - accuracy: 0.7237 - val_loss: 0.5819 - val_accuracy: 0.7087\n",
      "Epoch 49/150\n",
      "514/514 [==============================] - 0s 112us/step - loss: 0.5725 - accuracy: 0.7276 - val_loss: 0.8029 - val_accuracy: 0.5433\n",
      "Epoch 50/150\n",
      "514/514 [==============================] - 0s 109us/step - loss: 0.5803 - accuracy: 0.7062 - val_loss: 0.5934 - val_accuracy: 0.6969\n",
      "Epoch 51/150\n",
      "514/514 [==============================] - 0s 108us/step - loss: 0.5754 - accuracy: 0.7023 - val_loss: 0.5914 - val_accuracy: 0.7126\n",
      "Epoch 52/150\n",
      "514/514 [==============================] - 0s 113us/step - loss: 0.5545 - accuracy: 0.7237 - val_loss: 0.7753 - val_accuracy: 0.5669\n",
      "Epoch 53/150\n",
      "514/514 [==============================] - 0s 110us/step - loss: 0.5670 - accuracy: 0.7218 - val_loss: 0.6680 - val_accuracy: 0.6969\n",
      "Epoch 54/150\n",
      "514/514 [==============================] - 0s 113us/step - loss: 0.5768 - accuracy: 0.7023 - val_loss: 0.7651 - val_accuracy: 0.5512\n",
      "Epoch 55/150\n",
      "514/514 [==============================] - 0s 106us/step - loss: 0.5720 - accuracy: 0.7121 - val_loss: 0.6868 - val_accuracy: 0.6024\n",
      "Epoch 56/150\n",
      "514/514 [==============================] - 0s 106us/step - loss: 0.5657 - accuracy: 0.7198 - val_loss: 0.6313 - val_accuracy: 0.6654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/150\n",
      "514/514 [==============================] - 0s 104us/step - loss: 0.5587 - accuracy: 0.7374 - val_loss: 0.6139 - val_accuracy: 0.6378\n",
      "Epoch 58/150\n",
      "514/514 [==============================] - 0s 110us/step - loss: 0.5609 - accuracy: 0.7160 - val_loss: 0.7319 - val_accuracy: 0.6024\n",
      "Epoch 59/150\n",
      "514/514 [==============================] - 0s 102us/step - loss: 0.5633 - accuracy: 0.7140 - val_loss: 0.5610 - val_accuracy: 0.7244\n",
      "Epoch 60/150\n",
      "514/514 [==============================] - 0s 98us/step - loss: 0.5651 - accuracy: 0.7160 - val_loss: 0.6774 - val_accuracy: 0.5984\n",
      "Epoch 61/150\n",
      "514/514 [==============================] - 0s 103us/step - loss: 0.5451 - accuracy: 0.7451 - val_loss: 0.6274 - val_accuracy: 0.7008\n",
      "Epoch 62/150\n",
      "514/514 [==============================] - 0s 100us/step - loss: 0.5670 - accuracy: 0.7237 - val_loss: 0.6041 - val_accuracy: 0.7008\n",
      "Epoch 63/150\n",
      "514/514 [==============================] - 0s 107us/step - loss: 0.5572 - accuracy: 0.7023 - val_loss: 0.5843 - val_accuracy: 0.6850\n",
      "Epoch 64/150\n",
      "514/514 [==============================] - 0s 101us/step - loss: 0.5632 - accuracy: 0.7179 - val_loss: 0.6546 - val_accuracy: 0.7126\n",
      "Epoch 65/150\n",
      "514/514 [==============================] - 0s 98us/step - loss: 0.5719 - accuracy: 0.7023 - val_loss: 0.6147 - val_accuracy: 0.7087\n",
      "Epoch 66/150\n",
      "514/514 [==============================] - 0s 105us/step - loss: 0.5453 - accuracy: 0.7335 - val_loss: 0.7147 - val_accuracy: 0.6890\n",
      "Epoch 67/150\n",
      "514/514 [==============================] - 0s 100us/step - loss: 0.5422 - accuracy: 0.7315 - val_loss: 0.6351 - val_accuracy: 0.6732\n",
      "Epoch 68/150\n",
      "514/514 [==============================] - 0s 105us/step - loss: 0.5563 - accuracy: 0.7179 - val_loss: 0.5844 - val_accuracy: 0.7087\n",
      "Epoch 69/150\n",
      "514/514 [==============================] - 0s 102us/step - loss: 0.5587 - accuracy: 0.7237 - val_loss: 0.7321 - val_accuracy: 0.5669\n",
      "Epoch 70/150\n",
      "514/514 [==============================] - 0s 101us/step - loss: 0.5590 - accuracy: 0.7023 - val_loss: 0.6267 - val_accuracy: 0.6969\n",
      "Epoch 71/150\n",
      "514/514 [==============================] - 0s 108us/step - loss: 0.5466 - accuracy: 0.7354 - val_loss: 0.5881 - val_accuracy: 0.7205\n",
      "Epoch 72/150\n",
      "514/514 [==============================] - 0s 99us/step - loss: 0.5359 - accuracy: 0.7490 - val_loss: 0.8518 - val_accuracy: 0.5433\n",
      "Epoch 73/150\n",
      "514/514 [==============================] - 0s 107us/step - loss: 0.5586 - accuracy: 0.7004 - val_loss: 0.5822 - val_accuracy: 0.7244\n",
      "Epoch 74/150\n",
      "514/514 [==============================] - 0s 104us/step - loss: 0.5557 - accuracy: 0.7354 - val_loss: 0.6117 - val_accuracy: 0.6929\n",
      "Epoch 75/150\n",
      "514/514 [==============================] - 0s 108us/step - loss: 0.5503 - accuracy: 0.7335 - val_loss: 0.6401 - val_accuracy: 0.6654\n",
      "Epoch 76/150\n",
      "514/514 [==============================] - 0s 104us/step - loss: 0.5495 - accuracy: 0.7393 - val_loss: 0.5981 - val_accuracy: 0.7323\n",
      "Epoch 77/150\n",
      "514/514 [==============================] - 0s 114us/step - loss: 0.5517 - accuracy: 0.7412 - val_loss: 0.6496 - val_accuracy: 0.6496\n",
      "Epoch 78/150\n",
      "514/514 [==============================] - 0s 107us/step - loss: 0.5547 - accuracy: 0.7101 - val_loss: 0.5721 - val_accuracy: 0.6929\n",
      "Epoch 79/150\n",
      "514/514 [==============================] - 0s 118us/step - loss: 0.5361 - accuracy: 0.7335 - val_loss: 0.6786 - val_accuracy: 0.6378\n",
      "Epoch 80/150\n",
      "514/514 [==============================] - 0s 107us/step - loss: 0.5424 - accuracy: 0.7393 - val_loss: 0.6078 - val_accuracy: 0.6811\n",
      "Epoch 81/150\n",
      "514/514 [==============================] - 0s 111us/step - loss: 0.5433 - accuracy: 0.7510 - val_loss: 0.5883 - val_accuracy: 0.7087\n",
      "Epoch 82/150\n",
      "514/514 [==============================] - 0s 109us/step - loss: 0.5446 - accuracy: 0.7374 - val_loss: 0.5942 - val_accuracy: 0.6929\n",
      "Epoch 83/150\n",
      "514/514 [==============================] - 0s 107us/step - loss: 0.5459 - accuracy: 0.7237 - val_loss: 0.6336 - val_accuracy: 0.6614\n",
      "Epoch 84/150\n",
      "514/514 [==============================] - 0s 104us/step - loss: 0.5369 - accuracy: 0.7335 - val_loss: 0.6417 - val_accuracy: 0.7008\n",
      "Epoch 85/150\n",
      "514/514 [==============================] - 0s 110us/step - loss: 0.5544 - accuracy: 0.7101 - val_loss: 0.5860 - val_accuracy: 0.7283\n",
      "Epoch 86/150\n",
      "514/514 [==============================] - 0s 102us/step - loss: 0.5376 - accuracy: 0.7451 - val_loss: 0.5529 - val_accuracy: 0.7323\n",
      "Epoch 87/150\n",
      "514/514 [==============================] - 0s 101us/step - loss: 0.5442 - accuracy: 0.7296 - val_loss: 0.5966 - val_accuracy: 0.6969\n",
      "Epoch 88/150\n",
      "514/514 [==============================] - 0s 102us/step - loss: 0.5364 - accuracy: 0.7354 - val_loss: 0.5766 - val_accuracy: 0.7008\n",
      "Epoch 89/150\n",
      "514/514 [==============================] - 0s 98us/step - loss: 0.5316 - accuracy: 0.7490 - val_loss: 0.6711 - val_accuracy: 0.6378\n",
      "Epoch 90/150\n",
      "514/514 [==============================] - 0s 105us/step - loss: 0.5434 - accuracy: 0.7296 - val_loss: 0.6041 - val_accuracy: 0.6929\n",
      "Epoch 91/150\n",
      "514/514 [==============================] - 0s 114us/step - loss: 0.5388 - accuracy: 0.7451 - val_loss: 0.5587 - val_accuracy: 0.7323\n",
      "Epoch 92/150\n",
      "514/514 [==============================] - 0s 116us/step - loss: 0.5226 - accuracy: 0.7315 - val_loss: 0.6201 - val_accuracy: 0.7087\n",
      "Epoch 93/150\n",
      "514/514 [==============================] - 0s 113us/step - loss: 0.5376 - accuracy: 0.7315 - val_loss: 0.5710 - val_accuracy: 0.7126\n",
      "Epoch 94/150\n",
      "514/514 [==============================] - 0s 107us/step - loss: 0.5294 - accuracy: 0.7549 - val_loss: 0.7008 - val_accuracy: 0.6063\n",
      "Epoch 95/150\n",
      "514/514 [==============================] - 0s 108us/step - loss: 0.5212 - accuracy: 0.7490 - val_loss: 0.6481 - val_accuracy: 0.6850\n",
      "Epoch 96/150\n",
      "514/514 [==============================] - 0s 103us/step - loss: 0.5344 - accuracy: 0.7276 - val_loss: 0.5517 - val_accuracy: 0.7520\n",
      "Epoch 97/150\n",
      "514/514 [==============================] - 0s 103us/step - loss: 0.5426 - accuracy: 0.7393 - val_loss: 0.5836 - val_accuracy: 0.6890\n",
      "Epoch 98/150\n",
      "514/514 [==============================] - 0s 107us/step - loss: 0.5198 - accuracy: 0.7529 - val_loss: 0.5574 - val_accuracy: 0.7165\n",
      "Epoch 99/150\n",
      "514/514 [==============================] - 0s 102us/step - loss: 0.5337 - accuracy: 0.7374 - val_loss: 0.5904 - val_accuracy: 0.7087\n",
      "Epoch 100/150\n",
      "514/514 [==============================] - 0s 97us/step - loss: 0.5208 - accuracy: 0.7549 - val_loss: 0.5764 - val_accuracy: 0.7047\n",
      "Epoch 101/150\n",
      "514/514 [==============================] - 0s 100us/step - loss: 0.5244 - accuracy: 0.7510 - val_loss: 0.5475 - val_accuracy: 0.7441\n",
      "Epoch 102/150\n",
      "514/514 [==============================] - 0s 101us/step - loss: 0.5324 - accuracy: 0.7374 - val_loss: 0.8264 - val_accuracy: 0.5630\n",
      "Epoch 103/150\n",
      "514/514 [==============================] - 0s 107us/step - loss: 0.5248 - accuracy: 0.7393 - val_loss: 0.5931 - val_accuracy: 0.7087\n",
      "Epoch 104/150\n",
      "514/514 [==============================] - 0s 104us/step - loss: 0.5278 - accuracy: 0.7354 - val_loss: 0.6631 - val_accuracy: 0.7008\n",
      "Epoch 105/150\n",
      "514/514 [==============================] - 0s 102us/step - loss: 0.5389 - accuracy: 0.7296 - val_loss: 0.7287 - val_accuracy: 0.6024\n",
      "Epoch 106/150\n",
      "514/514 [==============================] - 0s 102us/step - loss: 0.5143 - accuracy: 0.7646 - val_loss: 0.5836 - val_accuracy: 0.7283\n",
      "Epoch 107/150\n",
      "514/514 [==============================] - 0s 106us/step - loss: 0.5222 - accuracy: 0.7237 - val_loss: 0.6121 - val_accuracy: 0.7047\n",
      "Epoch 108/150\n",
      "514/514 [==============================] - 0s 109us/step - loss: 0.5177 - accuracy: 0.7393 - val_loss: 0.5527 - val_accuracy: 0.7323\n",
      "Epoch 109/150\n",
      "514/514 [==============================] - 0s 100us/step - loss: 0.5186 - accuracy: 0.7607 - val_loss: 0.5563 - val_accuracy: 0.7205\n",
      "Epoch 110/150\n",
      "514/514 [==============================] - 0s 98us/step - loss: 0.5106 - accuracy: 0.7626 - val_loss: 0.6093 - val_accuracy: 0.7047\n",
      "Epoch 111/150\n",
      "514/514 [==============================] - 0s 104us/step - loss: 0.5254 - accuracy: 0.7393 - val_loss: 0.7082 - val_accuracy: 0.7008\n",
      "Epoch 112/150\n",
      "514/514 [==============================] - 0s 101us/step - loss: 0.5295 - accuracy: 0.7101 - val_loss: 0.5851 - val_accuracy: 0.7087\n",
      "Epoch 113/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514/514 [==============================] - 0s 101us/step - loss: 0.5166 - accuracy: 0.7588 - val_loss: 0.5994 - val_accuracy: 0.7126\n",
      "Epoch 114/150\n",
      "514/514 [==============================] - 0s 102us/step - loss: 0.5229 - accuracy: 0.7257 - val_loss: 0.5663 - val_accuracy: 0.7126\n",
      "Epoch 115/150\n",
      "514/514 [==============================] - 0s 104us/step - loss: 0.5285 - accuracy: 0.7451 - val_loss: 0.5617 - val_accuracy: 0.7047\n",
      "Epoch 116/150\n",
      "514/514 [==============================] - 0s 101us/step - loss: 0.5247 - accuracy: 0.7335 - val_loss: 0.6232 - val_accuracy: 0.6732\n",
      "Epoch 117/150\n",
      "514/514 [==============================] - 0s 103us/step - loss: 0.5159 - accuracy: 0.7510 - val_loss: 0.5994 - val_accuracy: 0.7205\n",
      "Epoch 118/150\n",
      "514/514 [==============================] - 0s 110us/step - loss: 0.5176 - accuracy: 0.7588 - val_loss: 0.5604 - val_accuracy: 0.7165\n",
      "Epoch 119/150\n",
      "514/514 [==============================] - 0s 100us/step - loss: 0.5192 - accuracy: 0.7393 - val_loss: 0.5843 - val_accuracy: 0.7126\n",
      "Epoch 120/150\n",
      "514/514 [==============================] - 0s 104us/step - loss: 0.5264 - accuracy: 0.7471 - val_loss: 0.5642 - val_accuracy: 0.7008\n",
      "Epoch 121/150\n",
      "514/514 [==============================] - 0s 98us/step - loss: 0.5137 - accuracy: 0.7529 - val_loss: 0.6210 - val_accuracy: 0.6772\n",
      "Epoch 122/150\n",
      "514/514 [==============================] - 0s 103us/step - loss: 0.5161 - accuracy: 0.7685 - val_loss: 0.5459 - val_accuracy: 0.7362\n",
      "Epoch 123/150\n",
      "514/514 [==============================] - 0s 108us/step - loss: 0.5199 - accuracy: 0.7335 - val_loss: 0.6062 - val_accuracy: 0.7008\n",
      "Epoch 124/150\n",
      "514/514 [==============================] - 0s 102us/step - loss: 0.5184 - accuracy: 0.7315 - val_loss: 0.6148 - val_accuracy: 0.6811\n",
      "Epoch 125/150\n",
      "514/514 [==============================] - 0s 109us/step - loss: 0.5189 - accuracy: 0.7626 - val_loss: 0.6157 - val_accuracy: 0.7047\n",
      "Epoch 126/150\n",
      "514/514 [==============================] - 0s 98us/step - loss: 0.5115 - accuracy: 0.7529 - val_loss: 0.5924 - val_accuracy: 0.7047\n",
      "Epoch 127/150\n",
      "514/514 [==============================] - 0s 103us/step - loss: 0.5067 - accuracy: 0.7510 - val_loss: 0.5686 - val_accuracy: 0.7205\n",
      "Epoch 128/150\n",
      "514/514 [==============================] - 0s 102us/step - loss: 0.5002 - accuracy: 0.7607 - val_loss: 0.7232 - val_accuracy: 0.6929\n",
      "Epoch 129/150\n",
      "514/514 [==============================] - 0s 109us/step - loss: 0.5137 - accuracy: 0.7529 - val_loss: 0.5537 - val_accuracy: 0.7283\n",
      "Epoch 130/150\n",
      "514/514 [==============================] - 0s 100us/step - loss: 0.5180 - accuracy: 0.7374 - val_loss: 0.7536 - val_accuracy: 0.5866\n",
      "Epoch 131/150\n",
      "514/514 [==============================] - 0s 100us/step - loss: 0.5214 - accuracy: 0.7315 - val_loss: 0.5643 - val_accuracy: 0.7283\n",
      "Epoch 132/150\n",
      "514/514 [==============================] - 0s 114us/step - loss: 0.5182 - accuracy: 0.7549 - val_loss: 0.6477 - val_accuracy: 0.7008\n",
      "Epoch 133/150\n",
      "514/514 [==============================] - 0s 110us/step - loss: 0.5151 - accuracy: 0.7607 - val_loss: 0.5709 - val_accuracy: 0.7283\n",
      "Epoch 134/150\n",
      "514/514 [==============================] - 0s 104us/step - loss: 0.5168 - accuracy: 0.7432 - val_loss: 0.5653 - val_accuracy: 0.7244\n",
      "Epoch 135/150\n",
      "514/514 [==============================] - 0s 109us/step - loss: 0.5105 - accuracy: 0.7510 - val_loss: 0.5586 - val_accuracy: 0.7165\n",
      "Epoch 136/150\n",
      "514/514 [==============================] - 0s 102us/step - loss: 0.5161 - accuracy: 0.7412 - val_loss: 0.6146 - val_accuracy: 0.6969\n",
      "Epoch 137/150\n",
      "514/514 [==============================] - 0s 114us/step - loss: 0.5106 - accuracy: 0.7549 - val_loss: 0.5410 - val_accuracy: 0.7480\n",
      "Epoch 138/150\n",
      "514/514 [==============================] - 0s 104us/step - loss: 0.5111 - accuracy: 0.7315 - val_loss: 0.5387 - val_accuracy: 0.7362\n",
      "Epoch 139/150\n",
      "514/514 [==============================] - 0s 103us/step - loss: 0.5103 - accuracy: 0.7510 - val_loss: 0.6117 - val_accuracy: 0.6772\n",
      "Epoch 140/150\n",
      "514/514 [==============================] - 0s 107us/step - loss: 0.5146 - accuracy: 0.7471 - val_loss: 0.5623 - val_accuracy: 0.7283\n",
      "Epoch 141/150\n",
      "514/514 [==============================] - 0s 110us/step - loss: 0.5088 - accuracy: 0.7374 - val_loss: 0.5448 - val_accuracy: 0.7323\n",
      "Epoch 142/150\n",
      "514/514 [==============================] - 0s 101us/step - loss: 0.5176 - accuracy: 0.7451 - val_loss: 0.5805 - val_accuracy: 0.7126\n",
      "Epoch 143/150\n",
      "514/514 [==============================] - 0s 97us/step - loss: 0.5082 - accuracy: 0.7412 - val_loss: 0.6467 - val_accuracy: 0.7008\n",
      "Epoch 144/150\n",
      "514/514 [==============================] - 0s 107us/step - loss: 0.5088 - accuracy: 0.7412 - val_loss: 0.5471 - val_accuracy: 0.7283\n",
      "Epoch 145/150\n",
      "514/514 [==============================] - 0s 104us/step - loss: 0.5075 - accuracy: 0.7529 - val_loss: 0.6402 - val_accuracy: 0.6969\n",
      "Epoch 146/150\n",
      "514/514 [==============================] - 0s 100us/step - loss: 0.5235 - accuracy: 0.7374 - val_loss: 0.5577 - val_accuracy: 0.7283\n",
      "Epoch 147/150\n",
      "514/514 [==============================] - 0s 100us/step - loss: 0.5093 - accuracy: 0.7490 - val_loss: 0.5878 - val_accuracy: 0.6890\n",
      "Epoch 148/150\n",
      "514/514 [==============================] - 0s 100us/step - loss: 0.5060 - accuracy: 0.7510 - val_loss: 0.5616 - val_accuracy: 0.7087\n",
      "Epoch 149/150\n",
      "514/514 [==============================] - 0s 103us/step - loss: 0.5104 - accuracy: 0.7510 - val_loss: 0.5468 - val_accuracy: 0.7362\n",
      "Epoch 150/150\n",
      "514/514 [==============================] - 0s 102us/step - loss: 0.5016 - accuracy: 0.7626 - val_loss: 0.6193 - val_accuracy: 0.6969\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model = create_model()\n",
    "history = model.fit(X, Y, validation_split=0.33, nb_epoch=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 13us/step\n",
      "\n",
      "accuracy: 72.14%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5715850902100404, 0.7213541865348816]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 72.14%\n"
     ]
    }
   ],
   "source": [
    "probabilities = model.predict(X)\n",
    "predictions = [float(np.round(x)) for x in probabilities]\n",
    "accuracy = np.mean(predictions == Y)\n",
    "print(\"Prediction Accuracy: %.2f%%\" % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss\n",
      "val_accuracy\n",
      "loss\n",
      "accuracy\n"
     ]
    }
   ],
   "source": [
    "for key in history.history.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.Exercise - Perform a StratifiedKfold validation using scikit-learn (*with the following parameters: n_splits=10, shuffle=True, random_state=seed*) - print mean result.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-21c09937675e>:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(12, input_dim=8, init=init, activation='relu'))\n",
      "<ipython-input-8-21c09937675e>:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(8, init=init, activation='relu'))\n",
      "<ipython-input-8-21c09937675e>:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(1, init=init, activation='sigmoid'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.35064936, 0.36363637, 0.50649351, 0.64935064, 0.58441556,\n",
       "       0.35064936, 0.59740257, 0.48051947, 0.53947371, 0.68421054])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# create model\n",
    "model_gs = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cross_val_score(estimator=model_gs, X=X, y=Y, cv=skf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.Exercise - Evaluate model with standardized inputs, using the same StratifiedKFold's parameters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-21c09937675e>:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(12, input_dim=8, init=init, activation='relu'))\n",
      "<ipython-input-8-21c09937675e>:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(8, init=init, activation='relu'))\n",
      "<ipython-input-8-21c09937675e>:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(1, init=init, activation='sigmoid'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 0s - loss: 0.9395 - accuracy: 0.3517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-21c09937675e>:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(12, input_dim=8, init=init, activation='relu'))\n",
      "<ipython-input-8-21c09937675e>:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(8, init=init, activation='relu'))\n",
      "<ipython-input-8-21c09937675e>:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(1, init=init, activation='sigmoid'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 0s - loss: 0.6622 - accuracy: 0.6715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-21c09937675e>:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(12, input_dim=8, init=init, activation='relu'))\n",
      "<ipython-input-8-21c09937675e>:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(8, init=init, activation='relu'))\n",
      "<ipython-input-8-21c09937675e>:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(1, init=init, activation='sigmoid'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 0s - loss: 0.6947 - accuracy: 0.5702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-21c09937675e>:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(12, input_dim=8, init=init, activation='relu'))\n",
      "<ipython-input-8-21c09937675e>:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(8, init=init, activation='relu'))\n",
      "<ipython-input-8-21c09937675e>:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(1, init=init, activation='sigmoid'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 0s - loss: 0.6093 - accuracy: 0.6946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-21c09937675e>:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(12, input_dim=8, init=init, activation='relu'))\n",
      "<ipython-input-8-21c09937675e>:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(8, init=init, activation='relu'))\n",
      "<ipython-input-8-21c09937675e>:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(1, init=init, activation='sigmoid'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 0s - loss: 0.7208 - accuracy: 0.5658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-21c09937675e>:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(12, input_dim=8, init=init, activation='relu'))\n",
      "<ipython-input-8-21c09937675e>:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(8, init=init, activation='relu'))\n",
      "<ipython-input-8-21c09937675e>:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(1, init=init, activation='sigmoid'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 0s - loss: 0.6400 - accuracy: 0.6397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-21c09937675e>:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(12, input_dim=8, init=init, activation='relu'))\n",
      "<ipython-input-8-21c09937675e>:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(8, init=init, activation='relu'))\n",
      "<ipython-input-8-21c09937675e>:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(1, init=init, activation='sigmoid'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 0s - loss: 0.7342 - accuracy: 0.4472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-21c09937675e>:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(12, input_dim=8, init=init, activation='relu'))\n",
      "<ipython-input-8-21c09937675e>:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(8, init=init, activation='relu'))\n",
      "<ipython-input-8-21c09937675e>:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(1, init=init, activation='sigmoid'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 0s - loss: 0.6991 - accuracy: 0.4790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-21c09937675e>:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(12, input_dim=8, init=init, activation='relu'))\n",
      "<ipython-input-8-21c09937675e>:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(8, init=init, activation='relu'))\n",
      "<ipython-input-8-21c09937675e>:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(1, init=init, activation='sigmoid'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 0s - loss: 0.7071 - accuracy: 0.4798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-21c09937675e>:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(12, input_dim=8, init=init, activation='relu'))\n",
      "<ipython-input-8-21c09937675e>:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(8, init=init, activation='relu'))\n",
      "<ipython-input-8-21c09937675e>:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(1, init=init, activation='sigmoid'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 0s - loss: 0.6578 - accuracy: 0.6503\n",
      "Standardized: 65.37% (8.85%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_model, nb_epoch=150, batch_size=10, verbose=2)))\n",
    "pipeline = Pipeline(estimators)\n",
    "\n",
    "# TODO - StratifiedKFold & cross_val_score \n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator=pipeline, X=X, y=Y, cv=skf)\n",
    "\n",
    "print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**3.Exercise - Perform a grid search to find the best hyperparameters for {optimizer, init_weights, epoch, batch} - NOTE: test two options, at your choice, for each parameter.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-21c09937675e>:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(12, input_dim=8, init=init, activation='relu'))\n",
      "<ipython-input-8-21c09937675e>:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(8, init=init, activation='relu'))\n",
      "<ipython-input-8-21c09937675e>:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(1, init=init, activation='sigmoid'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.619683 using {'nb_epoch': 10, 'optimizer': 'rmsprop'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# create model\n",
    "model_gs = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# grid search epochs, batch size and optimizer\n",
    "optimizers = ['Adam', 'rmsprop']\n",
    "init = []\n",
    "epochs = [10, 20]\n",
    "batches = []\n",
    "param_grid = dict(optimizer=optimizers, nb_epoch=epochs)\n",
    "\n",
    "# TODO - GridSearchCV & fit\n",
    "grid = GridSearchCV(model_gs, param_grid, cv=7)\n",
    "grid_result = grid.fit(X, Y)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean_fit_time', 'mean_score_time', 'mean_test_score', 'param_nb_epoch', 'param_optimizer', 'params', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'split5_test_score', 'split6_test_score', 'std_fit_time', 'std_score_time', 'std_test_score'] \n",
      "\n",
      "0.442428 (0.110049) with: {'nb_epoch': 10, 'optimizer': 'Adam'}\n",
      "0.619683 (0.106438) with: {'nb_epoch': 10, 'optimizer': 'rmsprop'}\n",
      "0.523520 (0.137369) with: {'nb_epoch': 20, 'optimizer': 'Adam'}\n",
      "0.455999 (0.129817) with: {'nb_epoch': 20, 'optimizer': 'rmsprop'}\n"
     ]
    }
   ],
   "source": [
    "print(sorted(grid.cv_results_.keys()), '\\n')\n",
    "\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "params = grid.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Exercise - Using the *history*, plot the *accuracy* and *loss*, on training *(accuracy, loss)* and on validation *(val_accuracy, val_loss)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# TODO - plotting the metrics\n",
    "fig = plt.figure()\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.Exercise - Serialize model to JSON format and weights to HDF5 format.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"class_name\": \"Sequential\",\n",
      "  \"config\": {\n",
      "    \"name\": \"sequential_1\",\n",
      "    \"layers\": [\n",
      "      {\n",
      "        \"class_name\": \"Dense\",\n",
      "        \"config\": {\n",
      "          \"name\": \"dense_1\",\n",
      "          \"trainable\": true,\n",
      "          \"batch_input_shape\": [\n",
      "            null,\n",
      "            8\n",
      "          ],\n",
      "          \"dtype\": \"float32\",\n",
      "          \"units\": 12,\n",
      "          \"activation\": \"relu\",\n",
      "          \"use_bias\": true,\n",
      "          \"kernel_initializer\": {\n",
      "            \"class_name\": \"VarianceScaling\",\n",
      "            \"config\": {\n",
      "              \"scale\": 1.0,\n",
      "              \"mode\": \"fan_avg\",\n",
      "              \"distribution\": \"uniform\",\n",
      "              \"seed\": null\n",
      "            }\n",
      "          },\n",
      "          \"bias_initializer\": {\n",
      "            \"class_name\": \"Zeros\",\n",
      "            \"config\": {}\n",
      "          },\n",
      "          \"kernel_regularizer\": null,\n",
      "          \"bias_regularizer\": null,\n",
      "          \"activity_regularizer\": null,\n",
      "          \"kernel_constraint\": null,\n",
      "          \"bias_constraint\": null\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"class_name\": \"Dense\",\n",
      "        \"config\": {\n",
      "          \"name\": \"dense_2\",\n",
      "          \"trainable\": true,\n",
      "          \"dtype\": \"float32\",\n",
      "          \"units\": 8,\n",
      "          \"activation\": \"relu\",\n",
      "          \"use_bias\": true,\n",
      "          \"kernel_initializer\": {\n",
      "            \"class_name\": \"VarianceScaling\",\n",
      "            \"config\": {\n",
      "              \"scale\": 1.0,\n",
      "              \"mode\": \"fan_avg\",\n",
      "              \"distribution\": \"uniform\",\n",
      "              \"seed\": null\n",
      "            }\n",
      "          },\n",
      "          \"bias_initializer\": {\n",
      "            \"class_name\": \"Zeros\",\n",
      "            \"config\": {}\n",
      "          },\n",
      "          \"kernel_regularizer\": null,\n",
      "          \"bias_regularizer\": null,\n",
      "          \"activity_regularizer\": null,\n",
      "          \"kernel_constraint\": null,\n",
      "          \"bias_constraint\": null\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"class_name\": \"Dense\",\n",
      "        \"config\": {\n",
      "          \"name\": \"dense_3\",\n",
      "          \"trainable\": true,\n",
      "          \"dtype\": \"float32\",\n",
      "          \"units\": 1,\n",
      "          \"activation\": \"sigmoid\",\n",
      "          \"use_bias\": true,\n",
      "          \"kernel_initializer\": {\n",
      "            \"class_name\": \"VarianceScaling\",\n",
      "            \"config\": {\n",
      "              \"scale\": 1.0,\n",
      "              \"mode\": \"fan_avg\",\n",
      "              \"distribution\": \"uniform\",\n",
      "              \"seed\": null\n",
      "            }\n",
      "          },\n",
      "          \"bias_initializer\": {\n",
      "            \"class_name\": \"Zeros\",\n",
      "            \"config\": {}\n",
      "          },\n",
      "          \"kernel_regularizer\": null,\n",
      "          \"bias_regularizer\": null,\n",
      "          \"activity_regularizer\": null,\n",
      "          \"kernel_constraint\": null,\n",
      "          \"bias_constraint\": null\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"keras_version\": \"2.3.1\",\n",
      "  \"backend\": \"tensorflow\"\n",
      "}\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "import os\n",
    "import json\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "print(json.dumps(json.loads(model_json), indent=2))\n",
    "with open(\"results/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"results/weights_json.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.Exercise - Load model from disk.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('results/model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"results/weights_json.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.Exercise - Provide a model checkpoint every time there is an improvement from previous epoch.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-65577374b902>:9: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  model.fit(X, Y, validation_split=0.33, nb_epoch=150, batch_size=10, callbacks=callbacks_list, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.72047, saving model to results/weights-improvement-01-0.72.hdf5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.72047\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.72047 to 0.72441, saving model to results/weights-improvement-03-0.72.hdf5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.72441\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.72441\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.72441\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.72441\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.72441 to 0.74409, saving model to results/weights-improvement-08-0.74.hdf5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.74409\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.74409 to 0.75591, saving model to results/weights-improvement-16-0.76.hdf5\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.75591\n",
      "\n",
      "Epoch 00103: val_accuracy improved from 0.75591 to 0.76378, saving model to results/weights-improvement-103-0.76.hdf5\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00120: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00134: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.76378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00144: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00146: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00147: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00149: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.76378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fb1f8503370>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# checkpoint\n",
    "filepath = \"results/weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# TODO - fit the model\n",
    "model.fit(X, Y, validation_split=0.33, nb_epoch=150, batch_size=10, callbacks=callbacks_list, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<keras.callbacks.callbacks.ModelCheckpoint object at 0x7fb1f8503dc0>]\n"
     ]
    }
   ],
   "source": [
    "print(callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8.Exercise - Provide a model checkpoint for the best training epoch.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-881fc0a552c3>:9: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  model.fit(X, Y, validation_split=0.33, nb_epoch=150, batch_size=10, callbacks=callbacks_list, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.71654, saving model to results/weights.best.hdf5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.71654\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.71654\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.71654 to 0.72441, saving model to results/weights.best.hdf5\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.72441 to 0.73228, saving model to results/weights.best.hdf5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.73228\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.73228 to 0.76378, saving model to results/weights.best.hdf5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.76378\n",
      "\n",
      "Epoch 00082: val_accuracy improved from 0.76378 to 0.77165, saving model to results/weights.best.hdf5\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00120: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00134: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00144: val_accuracy did not improve from 0.77165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00146: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00147: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00149: val_accuracy did not improve from 0.77165\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.77165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fb1f850cb80>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkpoint\n",
    "filepath = \"results/weights.best.hdf5\"\n",
    "# TODO - create model checkpoint\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "\n",
    "# TODO - fit the model\n",
    "model.fit(X, Y, validation_split=0.33, nb_epoch=150, batch_size=10, callbacks=callbacks_list, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Exercise - Create model and set weights from previous best checkpoint.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 40us/step\n",
      "accuracy: 79.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-46-0378e241d8ba>:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  load_model.add(Dense(12, input_dim=8, init='uniform', activation='relu'))\n",
      "<ipython-input-46-0378e241d8ba>:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  load_model.add(Dense(8, init='uniform', activation='relu'))\n",
      "<ipython-input-46-0378e241d8ba>:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "  load_model.add(Dense(1, init='uniform', activation='sigmoid'))\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "load_model = Sequential()\n",
    "load_model.add(Dense(12, input_dim=8, init='uniform', activation='relu'))\n",
    "load_model.add(Dense(8, init='uniform', activation='relu'))\n",
    "load_model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "\n",
    "# TODO - load weights\n",
    "load_model.load_weights(\"results/weights.best.hdf5\")\n",
    "\n",
    "# TODO - compile model \n",
    "load_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "scores = load_model.evaluate(X, Y)\n",
    "\n",
    "# TODO - estimate accuracy on whole dataset using loaded weights\n",
    "print(\"%s: %.2f%%\" % (load_model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5715850902100404, 0.7213541865348816]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. Exercise - Create model with dropout in the input layer with weight constraint, using standardized inputs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-47-8fa558c80bb2>:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(12, input_dim=8, init='glorot_uniform', activation='relu'))\n",
      "<ipython-input-47-8fa558c80bb2>:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(8, init='glorot_uniform', activation='relu'))\n",
      "<ipython-input-47-8fa558c80bb2>:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(1, init='glorot_uniform', activation='sigmoid'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 0s - loss: 0.8545 - accuracy: 0.3616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-47-8fa558c80bb2>:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(12, input_dim=8, init='glorot_uniform', activation='relu'))\n",
      "<ipython-input-47-8fa558c80bb2>:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(8, init='glorot_uniform', activation='relu'))\n",
      "<ipython-input-47-8fa558c80bb2>:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(1, init='glorot_uniform', activation='sigmoid'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 0s - loss: 0.6684 - accuracy: 0.5879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-47-8fa558c80bb2>:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(12, input_dim=8, init='glorot_uniform', activation='relu'))\n",
      "<ipython-input-47-8fa558c80bb2>:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(8, init='glorot_uniform', activation='relu'))\n",
      "<ipython-input-47-8fa558c80bb2>:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(1, init='glorot_uniform', activation='sigmoid'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 0s - loss: 0.7772 - accuracy: 0.4707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-47-8fa558c80bb2>:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(12, input_dim=8, init='glorot_uniform', activation='relu'))\n",
      "<ipython-input-47-8fa558c80bb2>:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(8, init='glorot_uniform', activation='relu'))\n",
      "<ipython-input-47-8fa558c80bb2>:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(1, init='glorot_uniform', activation='sigmoid'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 0s - loss: 0.6574 - accuracy: 0.6341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-47-8fa558c80bb2>:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(12, input_dim=8, init='glorot_uniform', activation='relu'))\n",
      "<ipython-input-47-8fa558c80bb2>:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(8, init='glorot_uniform', activation='relu'))\n",
      "<ipython-input-47-8fa558c80bb2>:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(1, init='glorot_uniform', activation='sigmoid'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 0s - loss: 0.7030 - accuracy: 0.5691\n",
      "Accuracy: 62.52% (10.36%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# dropout in the input layer with weight constraint\n",
    "def create_model_dropout_init():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dropout(0.2, input_shape=(8,)))\n",
    "    model.add(Dense(12, input_dim=8, init='glorot_uniform', activation='relu'))\n",
    "    \n",
    "    model.add(Dense(8, init='glorot_uniform', activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, init='glorot_uniform', activation='sigmoid'))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    return model\n",
    " \n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_model_dropout_init, nb_epoch=150, batch_size=10, verbose=2)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11. Exercise - Create model with dropout in hidden layers with weight constraint, using standardized inputs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-55-09647502846b>:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(12, input_dim=8, init='glorot_uniform', activation='relu'))\n",
      "<ipython-input-55-09647502846b>:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(8, init='glorot_uniform', activation='relu'))\n",
      "<ipython-input-55-09647502846b>:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(1, init='glorot_uniform', activation='sigmoid'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 0s - loss: 0.7669 - accuracy: 0.4446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-55-09647502846b>:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(12, input_dim=8, init='glorot_uniform', activation='relu'))\n",
      "<ipython-input-55-09647502846b>:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(8, init='glorot_uniform', activation='relu'))\n",
      "<ipython-input-55-09647502846b>:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(1, init='glorot_uniform', activation='sigmoid'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 0s - loss: 0.7033 - accuracy: 0.6336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-55-09647502846b>:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(12, input_dim=8, init='glorot_uniform', activation='relu'))\n",
      "<ipython-input-55-09647502846b>:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(8, init='glorot_uniform', activation='relu'))\n",
      "<ipython-input-55-09647502846b>:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(1, init='glorot_uniform', activation='sigmoid'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 0s - loss: 0.6624 - accuracy: 0.6498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-55-09647502846b>:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(12, input_dim=8, init='glorot_uniform', activation='relu'))\n",
      "<ipython-input-55-09647502846b>:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(8, init='glorot_uniform', activation='relu'))\n",
      "<ipython-input-55-09647502846b>:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(1, init='glorot_uniform', activation='sigmoid'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 0s - loss: 0.7324 - accuracy: 0.4634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-55-09647502846b>:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(12, input_dim=8, init='glorot_uniform', activation='relu'))\n",
      "<ipython-input-55-09647502846b>:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(8, init='glorot_uniform', activation='relu'))\n",
      "<ipython-input-55-09647502846b>:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model.add(Dense(1, init='glorot_uniform', activation='sigmoid'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 0s - loss: 0.7027 - accuracy: 0.5740\n",
      "Accuracy: 60.68% (5.12%)\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "# dropout in the input layer with weight constraint\n",
    "def create_model_dropout_init():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, init='glorot_uniform', activation='relu'))\n",
    "    model.add(Dropout(0.2, input_shape=(8,)))\n",
    "    model.add(Dense(8, init='glorot_uniform', activation='relu'))\n",
    "    model.add(Dropout(0.2, input_shape=(8,)))\n",
    "    model.add(Dense(1, init='glorot_uniform', activation='sigmoid'))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    return model\n",
    " \n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_model_dropout_init, nb_epoch=150, batch_size=10, verbose=2)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12.Exercise - Create a model with a decreasing decay rate, such as *decay_rate = learning_rate / epochs*, starting with *lr=0.1* and *epochs=50*, for a SGD optimizer with momemtum=0.8.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-0f43a2a084a3>:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model_sgd_lr.add(Dense(12, input_dim=8, init='glorot_uniform', activation='relu'))\n",
      "<ipython-input-50-0f43a2a084a3>:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model_sgd_lr.add(Dense(8, init='glorot_uniform', activation='relu'))\n",
      "<ipython-input-50-0f43a2a084a3>:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model_sgd_lr.add(Dense(1, init='glorot_uniform', activation='sigmoid'))\n",
      "<ipython-input-50-0f43a2a084a3>:18: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  model_sgd_lr.fit(X, Y, validation_split=0.33, nb_epoch=epochs, batch_size=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 514 samples, validate on 254 samples\n",
      "Epoch 1/50\n",
      "514/514 [==============================] - 0s 325us/step - loss: 7.8082 - accuracy: 0.6245 - val_loss: 0.6280 - val_accuracy: 0.6772\n",
      "Epoch 2/50\n",
      "514/514 [==============================] - 0s 128us/step - loss: 0.6601 - accuracy: 0.6401 - val_loss: 0.6328 - val_accuracy: 0.6732\n",
      "Epoch 3/50\n",
      "514/514 [==============================] - 0s 118us/step - loss: 0.6534 - accuracy: 0.6420 - val_loss: 0.6322 - val_accuracy: 0.6732\n",
      "Epoch 4/50\n",
      "514/514 [==============================] - 0s 131us/step - loss: 0.6532 - accuracy: 0.6420 - val_loss: 0.6322 - val_accuracy: 0.6732\n",
      "Epoch 5/50\n",
      "514/514 [==============================] - 0s 134us/step - loss: 0.6559 - accuracy: 0.6420 - val_loss: 0.6334 - val_accuracy: 0.6732\n",
      "Epoch 6/50\n",
      "514/514 [==============================] - 0s 130us/step - loss: 0.6545 - accuracy: 0.6420 - val_loss: 0.6334 - val_accuracy: 0.6732\n",
      "Epoch 7/50\n",
      "514/514 [==============================] - 0s 129us/step - loss: 0.6543 - accuracy: 0.6420 - val_loss: 0.6336 - val_accuracy: 0.6732\n",
      "Epoch 8/50\n",
      "514/514 [==============================] - 0s 166us/step - loss: 0.6569 - accuracy: 0.6420 - val_loss: 0.6336 - val_accuracy: 0.6732\n",
      "Epoch 9/50\n",
      "514/514 [==============================] - 0s 152us/step - loss: 0.6533 - accuracy: 0.6420 - val_loss: 0.6326 - val_accuracy: 0.6732\n",
      "Epoch 10/50\n",
      "514/514 [==============================] - 0s 168us/step - loss: 0.6533 - accuracy: 0.6420 - val_loss: 0.6355 - val_accuracy: 0.6732\n",
      "Epoch 11/50\n",
      "514/514 [==============================] - 0s 144us/step - loss: 0.6528 - accuracy: 0.6420 - val_loss: 0.6344 - val_accuracy: 0.6732\n",
      "Epoch 12/50\n",
      "514/514 [==============================] - 0s 144us/step - loss: 0.6536 - accuracy: 0.6420 - val_loss: 0.6323 - val_accuracy: 0.6732\n",
      "Epoch 13/50\n",
      "514/514 [==============================] - 0s 141us/step - loss: 0.6537 - accuracy: 0.6420 - val_loss: 0.6398 - val_accuracy: 0.6732\n",
      "Epoch 14/50\n",
      "514/514 [==============================] - 0s 140us/step - loss: 0.6525 - accuracy: 0.6420 - val_loss: 0.6347 - val_accuracy: 0.6732\n",
      "Epoch 15/50\n",
      "514/514 [==============================] - 0s 132us/step - loss: 0.6524 - accuracy: 0.6420 - val_loss: 0.6360 - val_accuracy: 0.6732\n",
      "Epoch 16/50\n",
      "514/514 [==============================] - 0s 146us/step - loss: 0.6533 - accuracy: 0.6420 - val_loss: 0.6360 - val_accuracy: 0.6732\n",
      "Epoch 17/50\n",
      "514/514 [==============================] - 0s 150us/step - loss: 0.6527 - accuracy: 0.6420 - val_loss: 0.6331 - val_accuracy: 0.6732\n",
      "Epoch 18/50\n",
      "514/514 [==============================] - 0s 146us/step - loss: 0.6526 - accuracy: 0.6420 - val_loss: 0.6359 - val_accuracy: 0.6732\n",
      "Epoch 19/50\n",
      "514/514 [==============================] - 0s 145us/step - loss: 0.6546 - accuracy: 0.6420 - val_loss: 0.6344 - val_accuracy: 0.6732\n",
      "Epoch 20/50\n",
      "514/514 [==============================] - 0s 148us/step - loss: 0.6521 - accuracy: 0.6420 - val_loss: 0.6339 - val_accuracy: 0.6732\n",
      "Epoch 21/50\n",
      "514/514 [==============================] - 0s 145us/step - loss: 0.6523 - accuracy: 0.6420 - val_loss: 0.6324 - val_accuracy: 0.6732\n",
      "Epoch 22/50\n",
      "514/514 [==============================] - 0s 148us/step - loss: 0.6528 - accuracy: 0.6420 - val_loss: 0.6339 - val_accuracy: 0.6732\n",
      "Epoch 23/50\n",
      "514/514 [==============================] - 0s 149us/step - loss: 0.6529 - accuracy: 0.6420 - val_loss: 0.6358 - val_accuracy: 0.6732\n",
      "Epoch 24/50\n",
      "514/514 [==============================] - 0s 156us/step - loss: 0.6516 - accuracy: 0.6420 - val_loss: 0.6334 - val_accuracy: 0.6732\n",
      "Epoch 25/50\n",
      "514/514 [==============================] - 0s 155us/step - loss: 0.6528 - accuracy: 0.6420 - val_loss: 0.6329 - val_accuracy: 0.6732\n",
      "Epoch 26/50\n",
      "514/514 [==============================] - 0s 144us/step - loss: 0.6526 - accuracy: 0.6420 - val_loss: 0.6331 - val_accuracy: 0.6732\n",
      "Epoch 27/50\n",
      "514/514 [==============================] - 0s 133us/step - loss: 0.6528 - accuracy: 0.6420 - val_loss: 0.6341 - val_accuracy: 0.6732\n",
      "Epoch 28/50\n",
      "514/514 [==============================] - 0s 136us/step - loss: 0.6522 - accuracy: 0.6420 - val_loss: 0.6339 - val_accuracy: 0.6732\n",
      "Epoch 29/50\n",
      "514/514 [==============================] - 0s 123us/step - loss: 0.6527 - accuracy: 0.6420 - val_loss: 0.6337 - val_accuracy: 0.6732\n",
      "Epoch 30/50\n",
      "514/514 [==============================] - 0s 125us/step - loss: 0.6528 - accuracy: 0.6420 - val_loss: 0.6346 - val_accuracy: 0.6732\n",
      "Epoch 31/50\n",
      "514/514 [==============================] - 0s 149us/step - loss: 0.6521 - accuracy: 0.6420 - val_loss: 0.6336 - val_accuracy: 0.6732\n",
      "Epoch 32/50\n",
      "514/514 [==============================] - 0s 134us/step - loss: 0.6521 - accuracy: 0.6420 - val_loss: 0.6347 - val_accuracy: 0.6732\n",
      "Epoch 33/50\n",
      "514/514 [==============================] - 0s 145us/step - loss: 0.6523 - accuracy: 0.6420 - val_loss: 0.6340 - val_accuracy: 0.6732\n",
      "Epoch 34/50\n",
      "514/514 [==============================] - 0s 140us/step - loss: 0.6520 - accuracy: 0.6420 - val_loss: 0.6336 - val_accuracy: 0.6732\n",
      "Epoch 35/50\n",
      "514/514 [==============================] - 0s 147us/step - loss: 0.6518 - accuracy: 0.6420 - val_loss: 0.6347 - val_accuracy: 0.6732\n",
      "Epoch 36/50\n",
      "514/514 [==============================] - 0s 142us/step - loss: 0.6538 - accuracy: 0.6420 - val_loss: 0.6341 - val_accuracy: 0.6732\n",
      "Epoch 37/50\n",
      "514/514 [==============================] - 0s 144us/step - loss: 0.6522 - accuracy: 0.6420 - val_loss: 0.6348 - val_accuracy: 0.6732\n",
      "Epoch 38/50\n",
      "514/514 [==============================] - 0s 145us/step - loss: 0.6521 - accuracy: 0.6420 - val_loss: 0.6356 - val_accuracy: 0.6732\n",
      "Epoch 39/50\n",
      "514/514 [==============================] - 0s 143us/step - loss: 0.6525 - accuracy: 0.6420 - val_loss: 0.6348 - val_accuracy: 0.6732\n",
      "Epoch 40/50\n",
      "514/514 [==============================] - 0s 141us/step - loss: 0.6531 - accuracy: 0.6420 - val_loss: 0.6342 - val_accuracy: 0.6732\n",
      "Epoch 41/50\n",
      "514/514 [==============================] - 0s 133us/step - loss: 0.6526 - accuracy: 0.6420 - val_loss: 0.6351 - val_accuracy: 0.6732\n",
      "Epoch 42/50\n",
      "514/514 [==============================] - 0s 141us/step - loss: 0.6521 - accuracy: 0.6420 - val_loss: 0.6342 - val_accuracy: 0.6732\n",
      "Epoch 43/50\n",
      "514/514 [==============================] - 0s 141us/step - loss: 0.6521 - accuracy: 0.6420 - val_loss: 0.6341 - val_accuracy: 0.6732\n",
      "Epoch 44/50\n",
      "514/514 [==============================] - 0s 147us/step - loss: 0.6523 - accuracy: 0.6420 - val_loss: 0.6340 - val_accuracy: 0.6732\n",
      "Epoch 45/50\n",
      "514/514 [==============================] - 0s 145us/step - loss: 0.6524 - accuracy: 0.6420 - val_loss: 0.6344 - val_accuracy: 0.6732\n",
      "Epoch 46/50\n",
      "514/514 [==============================] - 0s 150us/step - loss: 0.6522 - accuracy: 0.6420 - val_loss: 0.6342 - val_accuracy: 0.6732\n",
      "Epoch 47/50\n",
      "514/514 [==============================] - 0s 143us/step - loss: 0.6522 - accuracy: 0.6420 - val_loss: 0.6344 - val_accuracy: 0.6732\n",
      "Epoch 48/50\n",
      "514/514 [==============================] - 0s 133us/step - loss: 0.6521 - accuracy: 0.6420 - val_loss: 0.6346 - val_accuracy: 0.6732\n",
      "Epoch 49/50\n",
      "514/514 [==============================] - 0s 138us/step - loss: 0.6518 - accuracy: 0.6420 - val_loss: 0.6340 - val_accuracy: 0.6732\n",
      "Epoch 50/50\n",
      "514/514 [==============================] - 0s 143us/step - loss: 0.6523 - accuracy: 0.6420 - val_loss: 0.6338 - val_accuracy: 0.6732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fb1f75a7fa0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "# create model\n",
    "model_sgd_lr = Sequential()\n",
    "model_sgd_lr.add(Dense(12, input_dim=8, init='glorot_uniform', activation='relu'))\n",
    "model_sgd_lr.add(Dense(8, init='glorot_uniform', activation='relu'))\n",
    "model_sgd_lr.add(Dense(1, init='glorot_uniform', activation='sigmoid'))\n",
    "\n",
    "# compile model\n",
    "epochs = 50\n",
    "learning_rate = 0.1\n",
    "decay_rate = learning_rate / epochs\n",
    "momentum = 0.8\n",
    "sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "model_sgd_lr.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "model_sgd_lr.fit(X, Y, validation_split=0.33, nb_epoch=epochs, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**13.Exercise - Create a model with a learning rate scheduler for each epoch, with the following conditions:**\n",
    "* ***initial_lrate = 0.1***\n",
    "* ***drop = 0.5***\n",
    "* ***epochs_drop = 10.0***\n",
    "* ***lrate = initial_lrate $\\times$ math.pow(drop, math.floor((1+epoch)/epochs_drop))***\n",
    "\n",
    "**for the same SGD optimizer with momemtum**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.1\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.6485 - accuracy: 0.6510\n",
      "Epoch 2/150\n",
      "460/768 [================>.............] - ETA: 0s - loss: 0.6343 - accuracy: 0.6761"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-56-33880c747083>:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model_sgd_lr_schd.add(Dense(12, input_dim=8, init='glorot_uniform', activation='relu'))\n",
      "<ipython-input-56-33880c747083>:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model_sgd_lr_schd.add(Dense(8, init='glorot_uniform', activation='relu'))\n",
      "<ipython-input-56-33880c747083>:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\")`\n",
      "  model_sgd_lr_schd.add(Dense(1, init='glorot_uniform', activation='sigmoid'))\n",
      "<ipython-input-56-33880c747083>:21: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  model.fit(X, Y, nb_epoch=epochs, batch_size=10, callbacks=callbacks_list, verbose=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 110us/step - loss: 0.6516 - accuracy: 0.6510\n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.6499 - accuracy: 0.6510\n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.6461 - accuracy: 0.6510\n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.6538 - accuracy: 0.6510\n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.6525 - accuracy: 0.6510\n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.6523 - accuracy: 0.6510\n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.6509 - accuracy: 0.6510\n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.6523 - accuracy: 0.6510\n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.6503 - accuracy: 0.6510\n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.6492 - accuracy: 0.6510\n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.6490 - accuracy: 0.6510\n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.6492 - accuracy: 0.6510\n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s 117us/step - loss: 0.6492 - accuracy: 0.6510\n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.6497 - accuracy: 0.6510\n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s 109us/step - loss: 0.6496 - accuracy: 0.6510\n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s 111us/step - loss: 0.6491 - accuracy: 0.6510\n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.6492 - accuracy: 0.6510\n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.6496 - accuracy: 0.6510\n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.6492 - accuracy: 0.6510\n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.6478 - accuracy: 0.6510\n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.6480 - accuracy: 0.6510\n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.6478 - accuracy: 0.6510\n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.6485 - accuracy: 0.6510\n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.6480 - accuracy: 0.6510\n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 0s 111us/step - loss: 0.6484 - accuracy: 0.6510\n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.6475 - accuracy: 0.6510\n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s 112us/step - loss: 0.6487 - accuracy: 0.6510\n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.6482 - accuracy: 0.6510\n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.6476 - accuracy: 0.6510\n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.6467 - accuracy: 0.6510\n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s 112us/step - loss: 0.6478 - accuracy: 0.6510\n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s 117us/step - loss: 0.6476 - accuracy: 0.6510\n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.6478 - accuracy: 0.6510\n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s 109us/step - loss: 0.6475 - accuracy: 0.6510\n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 0s 112us/step - loss: 0.6476 - accuracy: 0.6510\n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s 126us/step - loss: 0.6474 - accuracy: 0.6510\n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s 93us/step - loss: 0.6473 - accuracy: 0.6510\n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s 115us/step - loss: 0.6477 - accuracy: 0.6510\n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s 109us/step - loss: 0.6473 - accuracy: 0.6510\n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.6473 - accuracy: 0.6510\n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s 109us/step - loss: 0.6471 - accuracy: 0.6510\n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.6472 - accuracy: 0.6510\n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 0s 113us/step - loss: 0.6472 - accuracy: 0.6510\n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.6472 - accuracy: 0.6510\n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.6471 - accuracy: 0.6510\n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s 111us/step - loss: 0.6472 - accuracy: 0.6510\n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.6473 - accuracy: 0.6510\n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s 89us/step - loss: 0.6472 - accuracy: 0.6510\n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s 90us/step - loss: 0.6471 - accuracy: 0.6510\n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.6471 - accuracy: 0.6510\n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s 93us/step - loss: 0.6470 - accuracy: 0.6510\n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.6470 - accuracy: 0.6510\n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s 114us/step - loss: 0.6470 - accuracy: 0.6510\n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.6470 - accuracy: 0.6510\n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.6470 - accuracy: 0.6510\n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.6470 - accuracy: 0.6510\n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.6471 - accuracy: 0.6510\n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.6470 - accuracy: 0.6510\n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.6469 - accuracy: 0.6510\n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s 106us/step - loss: 0.6469 - accuracy: 0.6510\n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s 113us/step - loss: 0.6469 - accuracy: 0.6510\n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s 105us/step - loss: 0.6469 - accuracy: 0.6510\n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.6469 - accuracy: 0.6510\n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s 114us/step - loss: 0.6469 - accuracy: 0.6510\n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s 107us/step - loss: 0.6470 - accuracy: 0.6510\n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s 108us/step - loss: 0.6469 - accuracy: 0.6510\n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 0s 112us/step - loss: 0.6469 - accuracy: 0.6510\n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s 110us/step - loss: 0.6469 - accuracy: 0.6510\n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.6469 - accuracy: 0.6510\n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.6469 - accuracy: 0.6510\n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.6469 - accuracy: 0.6510\n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.6469 - accuracy: 0.6510\n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.6469 - accuracy: 0.6510\n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.6469 - accuracy: 0.6510\n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.6469 - accuracy: 0.6510\n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.6469 - accuracy: 0.6510\n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 0s 89us/step - loss: 0.6469 - accuracy: 0.6510\n",
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 83/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 0s 90us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 0s 88us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 89/150\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s 91us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s 87us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s 92us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s 90us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s 93us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s 109us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s 104us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s 87us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s 93us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s 88us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s 87us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s 92us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s 100us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s 94us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s 86us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s 88us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s 92us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s 92us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s 92us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s 89us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s 92us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s 91us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s 99us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s 96us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s 101us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s 103us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s 102us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 0s 98us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s 95us/step - loss: 0.6468 - accuracy: 0.6510\n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 0s 97us/step - loss: 0.6468 - accuracy: 0.6510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fb1f8160b80>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "\n",
    "# create model\n",
    "model_sgd_lr_schd = Sequential()\n",
    "model_sgd_lr_schd.add(Dense(12, input_dim=8, init='glorot_uniform', activation='relu'))\n",
    "model_sgd_lr_schd.add(Dense(8, init='glorot_uniform', activation='relu'))\n",
    "model_sgd_lr_schd.add(Dense(1, init='glorot_uniform', activation='sigmoid'))\n",
    "\n",
    "# TODO - compile model\n",
    "epochs = 150\n",
    "decay = 0.0\n",
    "momentum = 0.8\n",
    "model_sgd_lr_schd.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "# learning scheduler callback\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "callbacks_list = [lrate]\n",
    "\n",
    "# TODO - fit the model with the learning scheduler callback\n",
    "model.fit(X, Y, nb_epoch=epochs, batch_size=10, callbacks=callbacks_list, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**14.Exercise - Create a smaller and a larger NN model and compare results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
