{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.\n",
    "*Exercise: Build a DNN with 20 hidden layers of 100 neurons each. Use He initialization and the ELU activation function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_valid = X_valid.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "\n",
    "#X_train = X_train.reshape(45000, 1024, 3)\n",
    "#X_valid = X_valid.reshape(5000, 1024, 3)\n",
    "#X_test = X_test.reshape(10000, 1024, 3)\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "Y_valid = np_utils.to_categorical(y_valid, n_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters / Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_units = 100\n",
    "activ_func = 'elu'\n",
    "init = 'he_normal'\n",
    "learning_rate = 0.005\n",
    "optim = keras.optimizers.Nadam(learning_rate)\n",
    "nb_epochs = 20\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 (20 Dense layers, 100 nodes deep - Softmax output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(13)\n",
    "np.random.seed(13)\n",
    "\n",
    "def Model1():\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(layers.Flatten(input_shape=X_valid.shape[1:]))\n",
    "    \n",
    "    for i in range(20):\n",
    "        model.add(layers.Dense(n_units, activation=activ_func, kernel_initializer=init))\n",
    "    \n",
    "    model.add(layers.Dense(n_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = Model1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./logs/run_13h45m_30-06'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Hh%Mm_%d-%m\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "tb_cb = callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ tensorboard --logdir=./logs --port=6006\n",
    "\n",
    "http://localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 2.0814 - accuracy: 0.2433 - val_loss: 2.2056 - val_accuracy: 0.2076\n",
      "Epoch 2/5\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.8525 - accuracy: 0.3269 - val_loss: 1.9307 - val_accuracy: 0.2994\n",
      "Epoch 3/5\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.7828 - accuracy: 0.3543 - val_loss: 1.8117 - val_accuracy: 0.3476\n",
      "Epoch 4/5\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.7284 - accuracy: 0.3787 - val_loss: 1.8126 - val_accuracy: 0.3436\n",
      "Epoch 5/5\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.6949 - accuracy: 0.3944 - val_loss: 1.7460 - val_accuracy: 0.3724\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=nb_epochs,\n",
    "                    validation_data=(X_valid, Y_valid), callbacks=[tb_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Common errors\n",
    "* ValueError: Input 0 of layer dense is incompatible with the layer: expected axis -1 of input shape to have value 1024 but received input with shape [None, 3072]\n",
    "* ValueError: Shapes (None, 10) and (None, 32, 32, 10) are incompatible # Concerning input reshape\n",
    "* ValueError: Shapes (None, 10) and (None, 1024, 10) are incompatible   # Concerning input reshape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\n",
    "*Exercise: Using Nadam optimization and early stopping, train the network on the CIFAR10 dataset. You can load it with `keras.datasets.cifar10.load_data()`. The dataset is composed of 60,000 32 × 32–pixel color images (50,000 for training, 10,000 for testing) with 10 classes, so you'll need a softmax output layer with 10 neurons. Remember to search for the right learning rate each time you change the model's architecture or hyperparameters.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(13)\n",
    "np.random.seed(13)\n",
    "\n",
    "def Model2(learning_rate=0.001, nb_epochs=5):\n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    #model.add(layers.Input(shape=X_train.shape[1:]))\n",
    "    model.add(layers.Flatten(input_shape=X_train.shape[1:]))\n",
    "    \n",
    "    for i in range(20):\n",
    "        model.add(layers.Dense(n_units, activation=activ_func, kernel_initializer=init))\n",
    "    \n",
    "    model.add(layers.Dense(n_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = Model2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some help:\n",
    "\n",
    "a. Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "X_train = X_train_full[5000:]\n",
    "y_train = y_train_full[5000:]\n",
    "X_valid = X_train_full[:5000]\n",
    "y_valid = y_train_full[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Fit and validate the model. \n",
    "**NOTE: please remember that firstly you need to create your model and compile it with the mentioned architecture and parameters. If you want to go further you can also add some callbacks for earlystopping, checkpoint serialization, tensorboard logging, among many others.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.269156 using {'learning_rate': 0.005, 'nb_epochs': 20}\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "grid_model = KerasClassifier(build_fn=Model2, verbose=0)\n",
    "\n",
    "# grid search epochs, batch size and optimizer\n",
    "#optim = []\n",
    "#init = []\n",
    "nb_epochs = [10, 20, 30]\n",
    "#batch_size = []\n",
    "lr = [0.001, 0.005, 0.01]\n",
    "param_grid = dict(learning_rate=lr, nb_epochs=nb_epochs)\n",
    "\n",
    "# TODO - GridSearchCV & fit\n",
    "grid = GridSearchCV(grid_model, param_grid, cv=3)\n",
    "grid_result = grid.fit(X_train, Y_train, validation_data=(X_valid, Y_valid))#, callbacks=[tb_cb])\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1024, 3) for input Tensor(\"flatten_52_input:0\", shape=(None, 1024, 3), dtype=float32), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 2.5476 - accuracy: 0.2235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.5475873947143555, 0.22351111471652985]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "history = model.fit(X_train, Y_train, epochs=nb_epochs, \n",
    "                    batch_size=batch_size, verbose=1, \n",
    "                    validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.fit(X_train, y_train, epochs=100,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.\n",
    "*Exercise: Now try adding Batch Normalization and compare the learning curves: Is it converging faster than before? Does it produce a better model? How does it affect training speed?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_units = 100\n",
    "activ_func = 'elu'\n",
    "init = 'he_normal'\n",
    "learning_rate = 0.01\n",
    "optim = keras.optimizers.Nadam(learning_rate)\n",
    "nb_epochs = 15\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(13)\n",
    "np.random.seed(13)\n",
    "\n",
    "def Model3(learning_rate=learning_rate, epochs=nb_epochs):\n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    #model.add(layers.Input(shape=X_train.shape[1:]))\n",
    "    model.add(layers.Flatten(input_shape=X_train.shape[1:]))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    \n",
    "    for i in range(20):\n",
    "        model.add(layers.Dense(n_units, activation=activ_func, kernel_initializer=init))\n",
    "        model.add(layers.BatchNormalization())\n",
    "    \n",
    "    model.add(layers.Dense(n_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = Model3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.436378 using {'epochs': 25, 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "grid_model = KerasClassifier(build_fn=Model3, verbose=0)\n",
    "\n",
    "# grid search epochs, batch size and optimizer\n",
    "#optim = []\n",
    "#init = []\n",
    "nb_epochs = [15, 25]\n",
    "#batch_size = []\n",
    "lr = [0.005, 0.01]\n",
    "param_grid = dict(learning_rate=lr, epochs=nb_epochs)\n",
    "\n",
    "# TODO - GridSearchCV & fit\n",
    "grid = GridSearchCV(grid_model, param_grid, cv=3)\n",
    "grid_result = grid.fit(X_train, Y_train, validation_data=(X_valid, Y_valid))#, callbacks=[tb_cb])\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 3.0865 - accuracy: 0.0918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.086491107940674, 0.09179999679327011]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.\n",
    "*Exercise: Try replacing Batch Normalization with SELU, and make the necessary adjustements to ensure the network self-normalizes (i.e., standardize the input features, use LeCun normal initialization, make sure the DNN contains only a sequence of dense layers, etc.).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "s_scaler = preprocessing.StandardScaler()\n",
    "X_train_scaled = s_scaler.fit_transform(X_train.reshape(45000, 3072)).reshape(45000, 1024, 3)\n",
    "X_valid_scaled = s_scaler.transform(X_valid.reshape(5000, 3072)).reshape(5000, 1024, 3)\n",
    "X_test_scaled = s_scaler.transform(X_test.reshape(10000, 3072)).reshape(10000, 1024, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 1024, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_units = 100\n",
    "activ_func = 'selu'\n",
    "init = 'lecun_normal'\n",
    "learning_rate = 0.002\n",
    "optim = keras.optimizers.Nadam(learning_rate)\n",
    "nb_epochs = 15\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(13)\n",
    "np.random.seed(13)\n",
    "\n",
    "def Model4(learning_rate=learning_rate, epochs=nb_epochs):\n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    #model.add(layers.Input(shape=X_train.shape[1:]))\n",
    "    model.add(layers.Flatten(input_shape=X_train_scaled.shape[1:]))\n",
    "    \n",
    "    for i in range(20):\n",
    "        model.add(layers.Dense(n_units, activation=activ_func, kernel_initializer=init))\n",
    "    \n",
    "    model.add(layers.Dense(n_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = Model4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "  2/352 [..............................] - ETA: 37:40 - loss: 3.0121 - accuracy: 0.1172WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (6.456300). Check your callbacks.\n",
      "352/352 [==============================] - 17s 47ms/step - loss: 2.0302 - accuracy: 0.2756 - val_loss: 1.9155 - val_accuracy: 0.3138\n",
      "Epoch 2/15\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 1.7865 - accuracy: 0.3650 - val_loss: 1.8294 - val_accuracy: 0.3616\n",
      "Epoch 3/15\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 1.6875 - accuracy: 0.4035 - val_loss: 1.7167 - val_accuracy: 0.3880\n",
      "Epoch 4/15\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 1.6187 - accuracy: 0.4290 - val_loss: 1.7082 - val_accuracy: 0.3862\n",
      "Epoch 5/15\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 1.5533 - accuracy: 0.4563 - val_loss: 1.6473 - val_accuracy: 0.4306\n",
      "Epoch 6/15\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 1.5251 - accuracy: 0.4665 - val_loss: 1.6416 - val_accuracy: 0.4324\n",
      "Epoch 7/15\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 1.4902 - accuracy: 0.4812 - val_loss: 1.6193 - val_accuracy: 0.4396\n",
      "Epoch 8/15\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 1.4503 - accuracy: 0.4965 - val_loss: 1.5949 - val_accuracy: 0.4496\n",
      "Epoch 9/15\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 1.4184 - accuracy: 0.5060 - val_loss: 1.5740 - val_accuracy: 0.4650\n",
      "Epoch 10/15\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 1.3979 - accuracy: 0.5143 - val_loss: 1.5430 - val_accuracy: 0.4666\n",
      "Epoch 11/15\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 1.3803 - accuracy: 0.5212 - val_loss: 1.5052 - val_accuracy: 0.4798\n",
      "Epoch 12/15\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 1.3462 - accuracy: 0.5363 - val_loss: 1.6507 - val_accuracy: 0.4526\n",
      "Epoch 13/15\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 1.3554 - accuracy: 0.5327 - val_loss: 1.5373 - val_accuracy: 0.4630\n",
      "Epoch 14/15\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 1.3292 - accuracy: 0.5401 - val_loss: 1.5794 - val_accuracy: 0.4710\n",
      "Epoch 15/15\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 1.3034 - accuracy: 0.5514 - val_loss: 1.5941 - val_accuracy: 0.4546\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, Y_train,\n",
    "          batch_size=128, epochs=nb_epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_valid_scaled, Y_valid), callbacks=[tb_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5640 - accuracy: 0.4678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5640168190002441, 0.46779999136924744]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.\n",
    "*Exercise: Try regularizing the model with alpha dropout. Check if there is any improvement or not.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_units = 100\n",
    "activ_func = 'selu'\n",
    "init = 'lecun_normal'\n",
    "learning_rate = 0.005\n",
    "optim = keras.optimizers.Nadam(learning_rate)\n",
    "nb_epochs = 15\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 1024, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(13)\n",
    "np.random.seed(13)\n",
    "\n",
    "def Model5(learning_rate=learning_rate, epochs=nb_epochs):\n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    #model.add(layers.Input(shape=X_train.shape[1:]))\n",
    "    model.add(layers.Flatten(input_shape=X_train_scaled.shape[1:]))\n",
    "    \n",
    "    for i in range(20):\n",
    "        model.add(layers.Dense(n_units, activation=activ_func, kernel_initializer=init))\n",
    "    \n",
    "    model.add(layers.AlphaDropout(rate=0.2))\n",
    "    model.add(layers.Dense(n_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = Model5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 2.2522 - accuracy: 0.1739 - val_loss: 14.6752 - val_accuracy: 0.1304\n",
      "Epoch 2/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 2.6237 - accuracy: 0.1048 - val_loss: 2.3922 - val_accuracy: 0.1038\n",
      "Epoch 3/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 2.3238 - accuracy: 0.1001 - val_loss: 2.3740 - val_accuracy: 0.1038\n",
      "Epoch 4/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 2.3264 - accuracy: 0.0989 - val_loss: 2.3875 - val_accuracy: 0.1010\n",
      "Epoch 5/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 2.3260 - accuracy: 0.0991 - val_loss: 2.3287 - val_accuracy: 0.1010\n",
      "Epoch 6/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 2.3257 - accuracy: 0.1007 - val_loss: 2.3957 - val_accuracy: 0.0920\n",
      "Epoch 7/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 2.3256 - accuracy: 0.0995 - val_loss: 2.3816 - val_accuracy: 0.1038\n",
      "Epoch 8/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 2.3259 - accuracy: 0.1004 - val_loss: 2.3423 - val_accuracy: 0.0996\n",
      "Epoch 9/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 2.3254 - accuracy: 0.1020 - val_loss: 2.3367 - val_accuracy: 0.0972\n",
      "Epoch 10/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 2.3262 - accuracy: 0.0990 - val_loss: 2.3451 - val_accuracy: 0.0920\n",
      "Epoch 11/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 2.3239 - accuracy: 0.1002 - val_loss: 2.3564 - val_accuracy: 0.1010\n",
      "Epoch 12/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 2.3259 - accuracy: 0.0976 - val_loss: 2.3948 - val_accuracy: 0.0976\n",
      "Epoch 13/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 2.3236 - accuracy: 0.1022 - val_loss: 2.3981 - val_accuracy: 0.0996\n",
      "Epoch 14/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 2.3242 - accuracy: 0.0987 - val_loss: 2.3884 - val_accuracy: 0.1040\n",
      "Epoch 15/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 2.3240 - accuracy: 0.0999 - val_loss: 2.4256 - val_accuracy: 0.1010\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, Y_train,\n",
    "          batch_size=128, epochs=nb_epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_valid_scaled, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 2.4253 - accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.425314426422119, 0.10000000149011612]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.\n",
    "*Exercise: Retrain your model using 1cycle scheduling and see if it improves training speed and model accuracy.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_units = 100\n",
    "activ_func = 'selu'\n",
    "init = 'lecun_normal'\n",
    "learning_rate = 0.01\n",
    "optim = keras.optimizers.Nadam(learning_rate)\n",
    "nb_epochs = 10\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model6(learning_rate=learning_rate, epochs=nb_epochs):\n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    #model.add(layers.Input(shape=X_train.shape[1:]))\n",
    "    model.add(layers.Flatten(input_shape=X_train_scaled.shape[1:]))\n",
    "    \n",
    "    for i in range(20):\n",
    "        model.add(layers.Dense(n_units, activation=activ_func, kernel_initializer=init))\n",
    "    \n",
    "    model.add(layers.AlphaDropout(rate=0.2))\n",
    "    model.add(layers.Dense(n_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = Model6()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.rates.append(K.get_value(self.model.optimizer.lr))\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)\n",
    "\n",
    "def find_learning_rate(model, X, y, epochs=1, batch_size=32, min_rate=10**-5, max_rate=10):\n",
    "    init_weights = model.get_weights()\n",
    "    iterations = len(X) // batch_size * epochs\n",
    "    factor = np.exp(np.log(max_rate / min_rate) / iterations)\n",
    "    init_lr = K.get_value(model.optimizer.lr)\n",
    "    K.set_value(model.optimizer.lr, min_rate)\n",
    "    exp_lr = ExponentialLearningRate(factor)\n",
    "    history = model.fit(X, y, epochs=epochs, batch_size=batch_size,\n",
    "                        callbacks=[exp_lr])\n",
    "    K.set_value(model.optimizer.lr, init_lr)\n",
    "    model.set_weights(init_weights)\n",
    "    return exp_lr.rates, exp_lr.losses\n",
    "\n",
    "def plot_lr_vs_loss(rates, losses):\n",
    "    plt.plot(rates, losses)\n",
    "    plt.gca().set_xscale('log')\n",
    "    plt.hlines(min(losses), min(rates), max(rates))\n",
    "    plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 2])\n",
    "    plt.xlabel(\"Learning rate\")\n",
    "    plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 4s 10ms/step - loss: inf - accuracy: 0.1464                    \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAERCAYAAABVU/GxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXyU5b338c8vCwkkJCxZ2GQJ+6KIoGKRRWtFcG1d2mo9x9pTbc+xts85XU6f1qfWo/bULq9z7Km29tHWUqtiH1sVcW9xRTSAoKyCEIIRSNgTSAjJ7/ljBhtjJmSSmbkzM9/363W/nNz3Nff8LkPyzXVvl7k7IiIi0coIugAREUlOChAREekUBYiIiHSKAkRERDpFASIiIp2iABERkU7JCrqARCoqKvLhw4cHXUbUdtcdoWrfYcaW9qZHljI/FR1tdtZ9cIBBfXrSP69H0OWIfMTy5ctr3L249fq0CpDhw4dTXl4edBlR27SrlnN+/iI3nj+ef5pZFnQ5Egc1tQ1Mu/V5brl4IlefMTzockQ+wswq2lqvP2eTwKiSfCaf0IeF5ZXoxk8R6S4UIEnis9NOYOPOWtZUHQi6FBERQAGSNM6ZUALAK5tqAq5ERCREAZIkSnrnMrokn9c27w66FBERQAGSVGaMKuLNLXs4crQ56FJERBQgyeTMUUUcbmzilU3VQZciIqIASSazxhTTP68HD79ZGXQpIiIKkGTSIyuDy6YO4YV1u9hd2xB0OSKS5hQgSeaikwdxtNl5Yf2uoEsRkTSnAEkyEwYWMLhPT55buzPoUkQkzSlAkoyZcc74El5+t5rDR5qCLkdE0pgCJAl9asIA6hubdVOhiARKAZKETi/rR+/cLJ5buyPoUkQkjSlAklB2ZgZnjS3hhXW7aGrWwxVFJBgKkCQ1Z2wxu+uOsH6HHq4oIsFQgCSp08v6A7DsvT0BVyIi6UoBkqQG9+nJCf16smyLHq4oIsFIWICYWY6Z3WtmFWZ20MxWmtm8dtqXmdmicNsaM7ujxbYlZlZvZrXhZUNietG9nD6iP29s2UOzzoOISAASOQLJAiqB2UAhcBOw0MyGt25oZj2A54C/AgOAIcAfWjW7wd3zw8vYONbdbZ05qoi9hxp5+/39QZciImkoYQHi7nXufrO7b3X3ZndfBGwBprbR/Bqgyt1/Hn5fvbuvTlStyWLWmGLM4G8b9FgTEUm8wM6BmFkpMAZY08bm6cBWM3sqfPhqiZmd2KrNj8LbXjWzOfGutzvql9eDKSf04W96LpaIBCCQADGzbOAB4H53X99GkyHA54A7gUHAk8Bj4UNbAN8ByoDBwD3AE2Y2MsJnXWdm5WZWXl2devNonDGyP+9UHdAkUyKScAkPEDPLABYAR4AbIjQ7DLzi7k+5+xHgp0B/YDyAuy9z94Pu3uDu9wOvAvPb2pG73+Pu09x9WnFxcay7E7iyonyamp3KvYeCLkVE0kxCA8TMDLgXKAUudffGCE1XA9FcWuSAdbG8pDS8KA+ArTV1AVciIukm0SOQuwmNIi5098PttPsDMN3MzjGzTOAbQA2wzsz6mNlcM8s1sywzuwqYBTwT9+q7obJwgGxRgIhIgmUl6oPMbBhwPdAA7AgNRiC87mVgLTDB3be5+wYz+wLwK6AEWAFc5O5HzKwQuBUYBzQB64FL3D0t7wXpm9eDwp7ZChARSbiEBYi7V9D+Yab8Vu0fBR5tYz/VwKmxrS65DS/KY+tuBYiIJJYeZZICRhbn8fb2/ezYXx90KSKSRhQgKeC6WWU0NTvfeHhl0KWISBpRgKSAcQMKuH72SF5/bw+7axuCLkdE0oQCJEXMHhO6x0XT3IpIoihAUsSkwYX07ZXNixtT7257EemeFCApIjPDmDO2hOfW7uTQkaNBlyMiaUABkkKuPH0oB+uP8vhbVUGXIiJpQAGSQqYN68uEgQXcsmgtj69SiIhIfClAUoiZcc8/TKWsOI//XLxOMxWKSFwpQFLMkL69uHbGCKr21/PW9n1BlyMiKUwBkoLOmVBKdqaxaNUHQZciIilMAZKCCnKzOXfCAB5ZXsnB+khPzBcR6RoFSIq6fnYZB+uP8uAb24IuRURSlAIkRZ00pA9Th/XlMV3SKyJxogBJYXMnlrKm6gDbNd2tiMSBAiSFfWrCAACeW7sz4EpEJBUpQFLYiKI8xpTm8+waBYiIxJ4CJMV9akIpb2zdw75DR4IuRURSjAIkxZ07YQBNzc4L63YFXYqIpBgFSIo7cXAhg/v05DE9G0tEYkwBkuIyMoxLTxnMy+9WU7XvcNDliEgKUYCkgcumnoA7uidERGJKAZIGhvbvxYSBBSzZoPMgIhI7CpA0MXtsMcsr9rJ0826ONjUHXY6IpAAFSJqYPaaYo83O53/zOnct2Rx0OSKSAhQgaWLqsL5cesoQAH776hbNmy4iXaYASRPZmRn87IrJPPKVM9h7qFHzpotIlylA0sy0YX0ZUZTHE6sVICLSNQqQNGNmXHjSQJZu3s2ug/VBlyNhrunrJQkpQNLQhZMH0ezw1Ns7gi5FWjMLugKRDktYgJhZjpnda2YVZnbQzFaa2bx22peZ2aJw2xozu6PFtn5m9mczqwvv78rE9CI1jC7tzbgBvXlCjzcRkS5I5AgkC6gEZgOFwE3AQjMb3rqhmfUAngP+CgwAhgB/aNHkl8ARoBS4CrjbzCbGsfaUc+HkQZRX7OV9Pd5ERDopYQHi7nXufrO7b3X3ZndfBGwBprbR/Bqgyt1/Hn5fvbuvBjCzPOBS4CZ3r3X3V4DHgasT1JWUcNHkQQD8ZeX7AVciIskqsHMgZlYKjAHWtLF5OrDVzJ4KH75aYmYnhreNAZrcfWOL9quANkcgZnadmZWbWXl1dXUsu5DUTujXi9NH9OOR8kpcZ3BFpBMCCRAzywYeAO539/VtNBkCfA64ExgEPAk8Fj60lQ/sb9V+P9C7rc9y93vcfZq7TysuLo5VF1LC5dNOYOvuQyyv2Bt0KSKShBIeIGaWASwgdA7jhgjNDgOvuPtT7n4E+CnQHxgP1AIFrdoXAAfjU3HqmjdpAL16ZPJI+fagSxGRJJTQADEzA+4ldPL7UndvjNB0NRDpuMpGIMvMRrdYN5m2D4VJO/Jysph/4kAWra6irkGPNhGR6CR6BHI3oVHEhe7e3uU/fwCmm9k5ZpYJfAOoAda5ex3wKHCLmeWZ2QzgYkKjGonSVacPpe5IE/e9siXoUkQkySTyPpBhwPXAycAOM6sNL1eZ2dDw66EA7r4B+ALwK2AvoYC4KHw4C+CfgZ7ALuBB4KvurhFIJ0wZ2pfzJg7gVy9upnLPoaDLEZEkkpWoD3L3CqC922zzW7V/lNBIo6197QEuiV116e17549n/p01/MsfV/DIV84gJysz6JJEJAnoUSbCCf168dPLJ7N6+35uXbQu6HJEJEkoQASAuRMHcM0nhrPg9Qo+2K+700Xk+BQg8qErTx8KwF/Xa+50ETk+BYh8aHRJPif068lf1ylAROT4FCDyITPj7LElvLq5hsam5qDLEZFuTgEiHzF1eD/qG5vZsEM39otI+xQg8hEnD+kDwKrt+wKuRES6OwWIfMQJ/XrSt1c2qytbP69SROSjFCDyEWbGSUP6aAQiIselAJGPmV7Wn/U7DrKlpi7oUkSkG1OAyMd85pTBZGYYC8srgy5FRLoxBYh8TGlBLmePK2HB0gpWVepQloi0TQEibfrhRRPpm5fNNx5+S1PeikibFCDSpkF9enLdzDK21NSxdbce8y4iH6cAkYhmjykBYMkGPdpERD5OASIRDe3fi7KiPP62oTroUkSkG1KASLvmThrAq5tq2HWgPuhSRKSbUYBIuy6fOoSmZufRle8HXYqIdDMKEGlXWXE+pw3vxwPLKmhq1tVYIvJ3ChA5ri/OGE7lnsM8u2ZH0KWISDeiAJHjOnfiAIb268Xvl1YEXYqIdCMKEDmuzAzjkimDWbZlN7sO6mS6iIQoQKRDLjhpIM0OT7+jw1giEqIAkQ4ZU9qbMaX5LFr9QdCliEg3oQCRDjv/xEG8uXUPO3VPiIigAJEonH/SQNxh8dsahYiIAkSiMKokn3EDevOkDmOJCDEIEDPLjkUhkhwuOGkg5RV7+WD/4aBLEZGARRUgZnajmV3a4ut7gcNmtsHMxsa8Oul2zj9pEIBGISIS9QjkRqAawMxmAVcAVwJvAT9r741mlmNm95pZhZkdNLOVZjYvQttrzKzJzGpbLHNabF9iZvUttm2Ish/SSSOK8pg8pJCF5ZWaaEokzUUbIIOBreHXFwKPuPtC4GZg+nHemwVUArOBQuAmYKGZDY/Qfqm757dYlrTafkOLbRr9JNDnTxvKxp21rNi2N+hSRCRA0QbIAaA4/PpTwAvh141AbntvdPc6d7/Z3be6e7O7LwK2AFOjrEECduHkQfTqkcmf9YRekbQWbYA8C/wmfO5jFPBUeP1EQmHQYWZWCowB1kRoMsXMasxso5ndZGZZrbb/KLz91ZaHtyT+8nKymDGqiCUbqnUYSySNRRsg/wK8ChQBl7n7nvD6U4AHO7qT8JVbDwD3u/v6Npq8BEwCSoBLgc8D32qx/TtAGaFDavcAT5jZyAifdZ2ZlZtZeXW1ZtaLlbPGlrB972E2V9cGXYqIBCSqAHH3A+7+NXe/2N2fbrH+B+5+e0f2YWYZwALgCHBDhM95z923hA91vQ3cAlzWYvsydz/o7g3ufj+hUJsfYV/3uPs0d59WXFzcVhPphDljQ/8vn1ur+dJF0lW0l/FOaHm5rpl9ysz+YGbfNbPMDrzfgHuBUuBSd2/s4Ec7YF3YLjE2qE9Ppgztw2Nv6TyISLqK9hDWvcAUADMbAjwG9CN0aOvWDrz/bmA8cKG7R7wTzczmhc+RYGbjCF2x9Vj46z5mNtfMcs0sy8yuAmYBz0TZF+miz0wZzPodB1lTtT/oUkQkANEGyHhgRfj15cAyd58PXE3oPEVEZjYMuB44GdjR4h6Oq8xsaPj10HDzTwKrzawOWAw8Chw7RJZNKKyqgRrga8Al7q57QRLsgpNCV2Pd8fQGnUwXSUOtr2w6nkxC5y4g9Et+cfj1ZkKHpSJy9wraP8yU36LtN4FvRthPNXBqB+uVOOqb14N/nzeO//PYGp5Zs5PzJg0IuiQRSaBoRyDvAF81s5mEAuTYifTBhEYDkmauOn0Yxb1zeHyVzoWIpJtoA+Q7wJeBJcCD4SukAC4C3ohhXZIkMjOMuRNL+dv6ag4faQq6HBFJoGgv432J0J3oRe5+bYtNvwa+GsvCJHnMnzSQw41NPKl5QkTSStSPc3f3JkJP4J1kZhPNLDf8eBLdEJCmppf158TBhfzs2Q0ahYikkWjvA8kys58Ae4FVwNvAXjO7Q/OCpK+MDOO788bxwf56zVYokkaiHYHcAXwB+Aqh51iNJnTo6mrgR7EtTZLJ9LL+lBbk8Py6nUGXIiIJEu1lvFcC17r74hbrNptZNfB/iXDpraS+jAzjk+NL+cvK96lvbCI3+7gPJhCRJBftCKSQ0D0frW0G+nS9HElm504o5dCRJpZs0EMro+XoRkxJPtEGyCpCsxK29vXwNkljZ44qorQgh4ff3BZ0KUlLD3STZBLtIaxvA4vN7FPAUkIPMTwDGAS0OT2tpI+szAwun3oCdy3ZxM4D9ZQWtDvHmIgkuc7cBzIGeITQo0cKwq/n0vbIRNLMeZMG0OywbMue4zcWkaQW7QgEd68CvtdynZlNJjTxk6S5cQN60zM7kxUVe7lo8qCgyxGROIr6RkKR9mRlZnDSkEJWVu4LuhQRiTMFiMTclKF9WVu1n/pG3ZUuksoUIBJzp43oS2OTs3Tz7qBLEZE46tA5EDN7/DhNCmJQi6SIGaOKKMjN4olVVZw1riTockQkTjp6Ev14f0ruBrZ0sRZJETlZmcybNJBFq6s4UN9IQa4ekyaSijoUIO7+xXgXIqnl6jOG8cjySm5dtJY7LpscdDkiEgc6ByJxMWlwIV+eVcbC8u1s3Hkw6HJEJA4UIBI3180so0dmBn94vSLoUkQkDhQgEjf983O44KSBLCyv5Ol3dgRdjojEmAJE4urf541jbGlvvvbgCnYeqA+6HBGJIQWIxFVJQS53fn4KR5udBUt1KEsklShAJO6G9c/jk+NKeejNbTQ3a94LkVShAJGEOG/SAGpqj7B+h67IEkkVChBJiBmj+gPw2uaagCsRkVhRgEhCDCzsSVlRHq/p+VgiKUMBIglz1rgSXn63mso9h4IuRURiQAEiCfPlmWVkmPHfL7wbdCkiEgMKEEmYAYW5XD19GI+u2M7m6tqgyxGRLkpYgJhZjpnda2YVZnbQzFaa2bwIba8xsyYzq22xzGmxvZ+Z/dnM6sL7uzJR/ZCu+cqckeRmZ3KnRiEiSS/qOdG7+FmVwGxgGzAfWGhmJ7r71jbaL3X3MyPs65fAEaAUOBl40sxWufua2JctsVSUn8PlU4fw0JuV1DYcJT8nkf8ERSSWEjYCcfc6d7/Z3be6e7O7LyI0h8jUaPZjZnnApcBN7l7r7q8AjwNXx75qiYcLJg+i4WgzL6zbGXQpItIFgZ0DMbNSYAwQadQwxcxqzGyjmd1kZsf+VB0DNLn7xhZtVwETI3zOdWZWbmbl1dXVMatfOm/q0L4MKMhlYXkl7rozXSRZBRIgZpYNPADc7+7r22jyEjAJKCE02vg88K3wtnxgf6v2+4HebX2Wu9/j7tPcfVpxcXEsypcuysgw/mnmCF7dtJvn1+0KuhwR6aSEB4iZZQALCJ3DuKGtNu7+nrtvCR/qehu4BbgsvLmWj8/BXgDoGRlJ5B8/MZzRJfncsmgN9Y1NQZcjIp2Q0AAxMwPuJXTy+1J3b+zgWx2w8OuNQJaZjW6xfTKRD4VJN5SdmcEPL5pI5Z7D/PrF94IuR0Q6IdEjkLuB8cCF7n44UiMzmxc+R4KZjQNuAh6D0Ml44FHgFjPLM7MZwMWERjWSRD4xqojzTxrIXUs26e50kSSUyPtAhgHXE7rsdkeL+zuuMrOh4ddDw80/Caw2szpgMaHAuL3F7v4Z6AnsAh4EvqpLeJPT9+aPJ8OM/3y6rVNhItKdJewifHev4O+HodqS36LtN4FvtrOvPcAlsatOgjKoT0++dOYI/udvm/jnOfuZOKgw6JJEpIP0KBMJ3JdnlVGQm8XPn914/MYi0m0oQCRwhT2zuX72SF5Yv4sV2/YGXY6IdJACRLqFaz4xnKL8Hvz0mQ1BlyIiHaQAkW4hLyeLr84ZxWubd/Obl97jaFNz0CWJyHEoQKTbuOr0oZw+oh+3LV6nOUNEkoACRLqN3OxMHrpuOhdNHsQ9L71H1b6ItwqJSDegAJFuxcz49nljaWp2fvvqlqDLEZF2KECk2xnStxfnTizlkeXb9ZwskW5MASLd0j+cMZx9hxr53D2vs+/QkaDLEZE2KECkW5pe1p+fXzGZtyr38cCybUGXIyJtUIBIt/WZU4Zw2oh+PKKJp0S6JQWIdGtXTDuBrbsPsfS93UGXIiKtKECkW7vgpIH0y+vBfa/oiiyR7kYBIt1abnYmX5g+jBfW7+K96tqgyxGRFhQg0u1dPX0Y2RkZ/PbVrUGXIiItKECk2yvuncMlUwbxyPJKNuw4yOOrqlj4ZmXQZYmkvYRNKCXSFTecNZpn1+5k7n+99OG6AYW5zBpTHGBVIulNIxBJCkP79+K315zKpacMYcGXTmNY/178x6K1NDXr8l6RoChAJGlMGdqXn10xmZmji/n23HG8u6uWxW9/EHRZImlLASJJad6kAYwqyee/nt9Iw1E9L0skCAoQSUoZGcb35o9nc3Udd2ruEJFAKEAkaZ01roRLTxnCr198jy01dUGXI5J2FCCS1L5z3lh6ZGVw++J1QZciknYUIJLUSgpyueHsUTy3didPrtYJdZFEUoBI0rtuZhmTBhdw25NrOXK0OehyRNKGAkSSXlZmBt88dyxV++t5dMX2oMvpFD2tXpKRAkRSwuwxxZw0pJC7lmzmaFPyjUIqdh8CYHCfngFXItJxChBJCWbG184ezbY9h3jsraqgy4naO+/vB2Di4IKAKxHpOAWIpIxzxpcwYWABP3t2A3UNR4MuJyrvVO2npHcOJb1zgy5FpMMSFiBmlmNm95pZhZkdNLOVZjavA+/7q5m5mWW1WLfEzOrNrDa8bIhv9ZIMzIxbLp5I1f567lqyKehyorLm/QNMGlwYdBkiUUnkCCQLqARmA4XATcBCMxse6Q1mdhWRnxh8g7vnh5exMa5VktS04f2Yf+IAFiyt4NCR5BiF1Dc28e6ug0wcpMNXklwSFiDuXufuN7v7VndvdvdFwBZgalvtzawQ+AHw7UTVKKnh2hkjOFB/lEdXvB90KR2y60ADzQ5D+/UKuhSRqAR2DsTMSoExwJoITW4H7gZ2RNj+IzOrMbNXzWxOHEqUJDV1WF8mDS7gd69txZPg+thdB+sBKC3Q+Q9JLoEEiJllAw8A97v7+ja2TwNmAL+IsIvvAGXAYOAe4AkzGxnhs64zs3IzK6+uro5J/dK9mRlf/MQINu2q5eV3a4Iu57h2HmgAFCCSfBIeIGaWASwAjgA3RNh+F/B1d2/zILa7L3P3g+7e4O73A68C8yO0vcfdp7n7tOJizV6XLi6YPJABBbn86Kn1NHbz+0J2Hjg2AskJuBKR6CQ0QMzMgHuBUuBSd29so1kBMA142Mx2AG+G1283s5kRdu2AxbpeSV45WZn88OKJrPvgAF/87Zu8v+9w0CVFtPNgPT2yMijsmR10KSJRSfQI5G5gPHChu0f6id4PDAJODi/HRhZTgWVm1sfM5ppZrpllha/UmgU8E+faJcnMnTiAH1w4gbcq93Hjgyu77fS3uw40UNI7h9DfVyLJI5H3gQwDricUCjta3MNxlZkNDb8e6iE7ji3AsRMXO939CJAN3BpeXwN8DbjE3XUviHzMF2eM4LZPT2J5xV4WLN0adDlt2nmgXuc/JClFusci5ty9gvYPM+VHeN/Wlu9z92rg1JgWJyntosmDWFheyX+/8C6fmTqEgtzudaho54F6xg7oHXQZIlHTo0wk5ZkZ3503nr2HGlmwtCLocj4mdAhLIxBJPgoQSQuTBhcyc3QRv1+6tVvNGXLkaDMHG47SP69H0KWIRE0BImnj2hkj2HmggYfe3BZ0KR869tDH/NyEHU0WiRkFiKSNOWOLmTGqPz95egObdh0MuhwAasMBkpejAJHkowCRtGFm3P7pE+mRlcGnf/kaK7btDbok6sIPfMxXgEgSUoBIWhnWP4/Hv3Ym/fJ78MXfvsm28EyAQanTCESSmAJE0s7gPj1ZcO3pNLvzjYdXBjoFbm1DEwD5OZmB1SDSWQoQSUtD+/fiPy6exIpt+3jozcrA6tAIRJKZAkTS1sUnD+K04f34+XMbA5t86sOT6D0UIJJ8FCCStsyMb503lj11R3j8rapAavjwMl6NQCQJKUAkrU0b1pexpb1Z8HpFIJNP6RCWJDMFiKQ1M+NLM0ewpuoA9726NeGfX9vQRI/MDHpk6UdRko/+1Urau3zqEM4ZX8qPn1pP5Z7EXtZb29BInq7AkiSlAJG0Z2bceskkMjLgx09/bIbluKpraNLhK0laChARYEBhLtfNGsmi1R+wvCJxd6jXNhzVCXRJWgoQkbDrZ5VR0juHWxatTdjshXUKEEliChCRsLycLP73/PGsqtzHBb94hSt+tZRHyiupb2yK22fWNRzVISxJWgoQkRYuPnkQcyeWsvNAPTV1DXzrT6s57bbn+fpDK3ljy56Yf54OYUky079ckRbMjLuumgpAhsGyLXt48I1tvLqphsVvf8D3z5/AZ089gdzs2Fw5FTqJrquwJDlpBCLSSmaGkZlhmBnTy/rz35+bwgv/NoczRhbxg8fXMPEHz/CH17s+Na67U6tDWJLEFCAiHVDYM5v7v3gq910zjdOG9+OWRWt5cWN1l/ZZsfsQtQ1HGVmcH6MqRRJLASLSQWbG2eNK+cWVUxhUmMs/3vcGDyzr/Ehk6Xu7AThjZP9YlSiSUAoQkSgV5efw9DdmMXN0EbcuWseaqv2d2s9rm3dT0juHsqK8GFcokhgKEJFOyM3O5I7LTqKwZzaX3b2UHz+9PqrLfZubnaWbdzO9rD9mFsdKReJHASLSSQMLe/L4DTM4e1wJdy/ZzPf/8k6Hn+j71vZ91NQ28MnxJXGuUiR+FCAiXVBSkMsvrzqFG88exZ+Wb+fpd3Z06H3PrNlBVoYxZ6wCRJKXrh8UiYEbPzmaZ9fu5NYn1zFnbAk9e/z93o6a2gb+6/mNLNlQTWNTM0ebnN11R5g5uojCntkBVi3SNQoQkRjIyszg5osm8rl7XufuFzfzr58aA8AH+w9z5W+WUbnnEOdOLCU/J4vMjAyG9O3J/BMHBly1SNcoQERiZHpZfy6cPIhfvbiZGSP7s6bqALctXkd2pvHQddOZNrxf0CWKxJQFMY1nUHr37u1Tp04NugxJYU1Zvdgx4bM05vYBjJ77K+hX8Vey6xP3iHiRWHvxxReXu/u01uvTKkDM7CCwoYu7KQSOd+F/e20ibWu9vr2vI70uAmqOU1t7OtK347WLV/+62rf2aoumXVvbOrIulfsXqa+x/LcZqY5o20X7vWr9dbx+9iLVFk2beP5uGebuxR/bs7unzQKUx2Af93SlTaRtrde393U7r7vUv470Laj+Jep715n+dWRdKvcvUl9j+W8zkf0L4mevo/0L6ndLpEWX8UbviS62ibSt9fr2vo70uqs6ui/1L/p1qdy/SH2NZd+i2V9X+xfE966j++tWP3vpdgir3Ns4jpcqUrl/qdw3UP+SXar3L5J0G4HcE3QBcZbK/UvlvoH6l+xSvX9tSqsRiIiIxE66jUBERCRGFCAiItIpCpAWzGy4mVWb2ZLw8vHrnlOAmX3ezLo2nV43ZGalZvaamb1oZn81s5R6VoiZnWFmS8P9e9DMUupBWmZWaGZvmFmtmU0Kup5YMLPbzOxlM/uTmfUKup5YU4B83IvuPie8pOIv2QzgMqAy6FrioAY4091nA78HvhRwPbFWAZwd7t97wMUB1xNrh4DzgRN7SYgAAAcHSURBVD8FXUgshENwpLvPBJ4Hrg24pJhTgHzcjPBfDLdbas70cyWhH9DmoAuJNXdvcvdj/eoNrAmynlhz9yp3Pxz+8igp9j1098YU+6NtJvBU+PVTwJkB1hIXSRsgZnaDmZWbWYOZ/a7Vtn5m9mczqzOzCjO7soO7/QAYBcwCSoDPxLbqjotH/8wsE7gCeDgOJUclTt8/zOxkM1sG3ACsiHHZHRav/oXfPwKYByyKYclRiWf/upsu9LUvf38UyH4g5Z6mmcxP460CbgXmAj1bbfslcAQoBU4GnjSzVe6+xswG0PYQ+TJ33wE0AJjZo8B04P/Fqf7jiXn/wvta6O7N3WBwFZfvn7u/BZxuZlcA3wW+ErcetC8u/TOzAuB+4Gp3PxK/8o8rXj9/3VGn+grsJfQ8KcL/3ZOYchOoq89vCXoh9I39XYuv8wh9Q8e0WLcA+M8O7KugxesfAf+QYv37MfAs8DShv4juTLH+5bR4PRf4eYr1Lwt4ktB5kED7FY/+tWj/O2BS0H3ral+BE4E/hl9fB3wt6D7EeknaQ1jtGAM0ufvGFutWARM78N7ZZrbczF4GBgN/jEeBXdTp/rn7d9z9XHc/D3jX3W+MV5Fd0JXv3ylm9pKZ/Q34BvCTeBTYRV3p3+eB04H/E75K8LPxKLCLutI/zGwxcC7wGzO7JvblxVS7fXX3t4GK8O+TucB9iS8xvpL5EFYk+Xz8kcb7CZ1UbZe7P0HsH5AWa53uX0vefZ/b05Xv31JC56+6s670bwGhv3C7sy79+3T3+TGvKH6O21d3/25CK0qwVByB1AIFrdYVAAcDqCUe1L/kpv6ljnTqa5tSMUA2AllmNrrFusmkziWd6l9yU/9SRzr1tU1JGyBmlmVmuUAmkGlmuWaW5e51wKPALWaWZ2YzCN1w1d2H/h+h/ql/3Vmq96+ldOpr1II+i9+FKyJuBrzVcnN4Wz/gL0AdsA24Muh61T/1T/1LziWd+hrtose5i4hIpyTtISwREQmWAkRERDpFASIiIp2iABERkU5RgIiISKcoQEREpFMUICIi0ikKEJEEMbObzeydoOsQiRXdSCgpJTxjXJG7XxB0La2ZWT6hOUt2B11LJGbmwOXunhLzkkt8aQQi0kVm1qMj7dy9NojwMLOM8HTGIjGlAJG0YmYTzOxJMztoZrvM7MHwNKvHtp9qZs+aWY2ZHTCzV8zsjFb7cDP7FzN71MzqgNuPHZ4ys8+Z2ebw/v9iZkUt3veRQ1hm9jszW2RmXzez981sr5n91sx6tWiTZ2a/N7NaM9tpZt8Nv+d37fTxmnD7+eHPOwKMP17fzGxr+OUj4T5ubbHtwvBka/VmtsXMbutocErqUoBI2jCzgcBLwDvAacA5hCYFetzMjv0s9Cb0NNWZ4TZvAYtbBkHYD4DFhKYt/WV43XDgs8CnCc2qNwW47ThlzQQmhWs59t6vt9j+M2B2eP3ZhB4XPrMD3c0Fvg9cD0wAKjrQt1PD//0yMPDY12Y2F3gA+B9Cs+1dC1wG3N6BOiSVBf00Ry1aYrkQmk97UYRttwAvtFrXl9DTVU+L8B4DPgC+0GKdA79o1e5moB4obLHue8CmVm3eaVVrJZDVYt1vgOfDr/MJjR4+12J7HrCXFnNzt1HzNeEapx7n/1Wkvl3Wqt1LwE2t1l1CaEIlC/p7riW4RSMQSSdTgVnhwzu1ZlZL6Bc4wEgAMysxs1+b2UYz209odrkSYGirfZW3sf8Kd285xWlV+L3tWevuRyO8ZySQDbxxbKOH5qDoyJVcRwmNMD4URd9amwp8r9X/tz8SCrMB7b9VUlkqzokuEkkG8CTwzTa27Qz/936gFPhfwFagAXgBaH28v66NfTS2+to5/mHi9t5jLdZFq8Hdm1qt62jfWssAfgg80sa26k7UJilCASLpZAVwBaGRQutf3MecCdzo7k8CmFkpofMBQdhEKGBOA7aE6+lF6JzJ5k7sryN9ayQ0815LK4Bx7r6pE58pKUwBIqmowMxObrVuH6GT3V8GHjazHxP667mMUKj8m7sfJDTP9RfMbBmhQzR3EDoPkXDuXmtm9wE/NrMaQucrvk9oRNCZUUlH+rYV+KSZvUhoFLOX0LmjRWZWASwkdHhsEqHzRt/uRB2SInQORFLRTGBlq+Wn7l4FzACagaeBNYRCpSG8QOgKo3xgOfAQcB+hX6pB+SbwMvA48DdgNaHzL/Wd2FdH+vZvwFmEzg2tBHD3Z4Dzw+vfCC//TmgKV0ljuhNdJImYWQ6hS3J/4u4/C7oeSW86hCXSjZnZFGA8ob/6ewPfCf/34SDrEgEFiEgy+FdgLH+/NHeWu28PtiQRHcISEZFO0kl0ERHpFAWIiIh0igJEREQ6RQEiIiKdogAREZFOUYCIiEin/H8iP99yaUcThAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rates, losses = find_learning_rate(model, X_train_scaled, Y_train, epochs=1, batch_size=batch_size)\n",
    "plot_lr_vs_loss(rates, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneCycleScheduler(keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_rate, start_rate=None,\n",
    "                 last_iterations=None, last_rate=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_rate = max_rate\n",
    "        self.start_rate = start_rate or max_rate / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_rate = last_rate or self.start_rate / 1000\n",
    "        self.iteration = 0\n",
    "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
    "        return ((rate2 - rate1) * (self.iteration - iter1)\n",
    "                / (iter2 - iter1) + rate1)\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "                                     self.max_rate, self.start_rate)\n",
    "        else:\n",
    "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "                                     self.start_rate, self.last_rate)\n",
    "            rate = max(rate, self.last_rate)\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.lr, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "352/352 [==============================] - 4s 10ms/step - loss: 2.1563 - accuracy: 0.2314 - val_loss: 1.9917 - val_accuracy: 0.3062\n",
      "Epoch 2/20\n",
      "352/352 [==============================] - 4s 10ms/step - loss: 1.9537 - accuracy: 0.2927 - val_loss: 2.0000 - val_accuracy: 0.3024\n",
      "Epoch 3/20\n",
      "352/352 [==============================] - 4s 10ms/step - loss: 1.9125 - accuracy: 0.3110 - val_loss: 1.9313 - val_accuracy: 0.3042\n",
      "Epoch 4/20\n",
      "352/352 [==============================] - 4s 10ms/step - loss: 1.8938 - accuracy: 0.3206 - val_loss: 1.9644 - val_accuracy: 0.3036\n",
      "Epoch 5/20\n",
      "352/352 [==============================] - 4s 10ms/step - loss: 1.8887 - accuracy: 0.3256 - val_loss: 1.9515 - val_accuracy: 0.3008\n",
      "Epoch 6/20\n",
      "352/352 [==============================] - 4s 10ms/step - loss: 1.8950 - accuracy: 0.3216 - val_loss: 2.0607 - val_accuracy: 0.2820\n",
      "Epoch 7/20\n",
      "352/352 [==============================] - 4s 10ms/step - loss: 1.8932 - accuracy: 0.3232 - val_loss: 1.9970 - val_accuracy: 0.2890\n",
      "Epoch 8/20\n",
      "352/352 [==============================] - 4s 10ms/step - loss: 1.8885 - accuracy: 0.3247 - val_loss: 1.9970 - val_accuracy: 0.3208\n",
      "Epoch 9/20\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 1.8932 - accuracy: 0.3232 - val_loss: 1.9595 - val_accuracy: 0.2926\n",
      "Epoch 10/20\n",
      "352/352 [==============================] - 4s 10ms/step - loss: 1.8867 - accuracy: 0.3261 - val_loss: 2.0105 - val_accuracy: 0.2898\n",
      "Epoch 11/20\n",
      "352/352 [==============================] - 4s 10ms/step - loss: 1.8650 - accuracy: 0.3307 - val_loss: 1.9690 - val_accuracy: 0.2968\n",
      "Epoch 12/20\n",
      "352/352 [==============================] - 4s 10ms/step - loss: 1.8589 - accuracy: 0.3340 - val_loss: 2.2989 - val_accuracy: 0.2126\n",
      "Epoch 13/20\n",
      "352/352 [==============================] - 4s 10ms/step - loss: 1.9246 - accuracy: 0.3026 - val_loss: 1.9191 - val_accuracy: 0.3106\n",
      "Epoch 14/20\n",
      "352/352 [==============================] - 4s 10ms/step - loss: 1.8777 - accuracy: 0.3244 - val_loss: 1.9571 - val_accuracy: 0.3034\n",
      "Epoch 15/20\n",
      "352/352 [==============================] - 4s 10ms/step - loss: 1.8266 - accuracy: 0.3480 - val_loss: 1.8681 - val_accuracy: 0.3230\n",
      "Epoch 16/20\n",
      "352/352 [==============================] - 4s 10ms/step - loss: 1.7962 - accuracy: 0.3580 - val_loss: 1.8857 - val_accuracy: 0.3386\n",
      "Epoch 17/20\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 1.7669 - accuracy: 0.3697 - val_loss: 1.8609 - val_accuracy: 0.3412\n",
      "Epoch 18/20\n",
      "352/352 [==============================] - 4s 10ms/step - loss: 1.7372 - accuracy: 0.3805 - val_loss: 1.8795 - val_accuracy: 0.3552\n",
      "Epoch 19/20\n",
      "352/352 [==============================] - 4s 10ms/step - loss: 1.7098 - accuracy: 0.3897 - val_loss: 1.8398 - val_accuracy: 0.3614\n",
      "Epoch 20/20\n",
      "352/352 [==============================] - 4s 10ms/step - loss: 1.6855 - accuracy: 0.3983 - val_loss: 1.8448 - val_accuracy: 0.3636\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "onecycle = OneCycleScheduler(len(X_train_scaled) // batch_size * nb_epochs, max_rate=0.05)\n",
    "history = model.fit(X_train_scaled, Y_train, epochs=nb_epochs, batch_size=batch_size,\n",
    "                    validation_data=(X_valid_scaled, Y_valid),\n",
    "                    callbacks=[onecycle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.8155 - accuracy: 0.3755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8154945373535156, 0.37549999356269836]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
